<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2022-05-17T09:07:31+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Switching to Java 11/17</title><link href="https://debezium.io/blog/2022/05/04/switch-to-java-11/" rel="alternate" type="text/html" title="Switching to Java 11/17"/><published>2022-05-04T00:00:00+00:00</published><updated>2022-05-04T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/05/04/switch-to-java-11</id><content type="html" xml:base="https://debezium.io/blog/2022/05/04/switch-to-java-11/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As you probably noticed, we have started work on Debezium 2.0. One of &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;the planned changes&lt;/a&gt; for the 2.0 release is &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4949&quot;&gt;to switch to Java 11 as a baseline&lt;/a&gt;. While some Java build providers still support Java 8, other Java 8 distributions already reached their end of life/support. Users are moving to Java 11 anyways, as surveys like New Relic&amp;#8217;s &lt;a href=&quot;https://newrelic.com/resources/report/2022-state-of-java-ecosystem&quot;&gt;State of the Java Ecosystem Report&lt;/a&gt; indicate. But it is not only matter of support: Java 11 comes with various performance improvements, useful tools like JDK Flight Recorder, which was open-sourced in Java 11, and more. So we felt it was about time to start thinking about using a more recent JDK as the baseline for Debezium, and the new major release is a natural milestone when to do the switch.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Starting with the first release of Debezium 2.0, &lt;a href=&quot;/blog/2022/04/28/debezium-2.0-alpha1-released/&quot;&gt;2.0.0.Alpha1&lt;/a&gt;, Debezium bits will be compiled to Java 11 byte code. Therefore, Java 11 will be required to run Debezium in the next major update. Also, if you use any of the Debezium bits as a library in your project (using the Debezium &lt;a href=&quot;/documentation/reference/stable/development/engine.html&quot;&gt;embedded engine&lt;/a&gt;), you will have to switch to Java 11.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But wait, what does Java 11/17 in the title mean? Is it there just to scare you, or we are going to actually switch to Java 17 right away?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&amp;lt;dramatic pause here&amp;gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;No, we don&amp;#8217;t want to scare you. We are actually planning to switch to Java 17, but only for the test suite. Please note that both Java 11 and 17 are long term support (LTS) releases. We don&amp;#8217;t want to move Java 17 for the actual Debezium artifacts just yet, as it can be an issue for substantial amount of Debezium users; as e.g. the aforementioned New Relic report shows that most of the users are still on Java 11 and of course we don&amp;#8217;t want to exclude them. However, using Java 17 for tests doesn&amp;#8217;t affect users in any way, and will allow us to use some more recent Java features in the tests, like e.g. * &lt;a href=&quot;https://openjdk.java.net/jeps/378&quot;&gt;text blocks&lt;/a&gt;, which for instance simplify the usage of multi-line JSON or SQL strings, * &lt;a href=&quot;https://openjdk.java.net/jeps/384&quot;&gt;records&lt;/a&gt;, which can improve readability of the stream operations heavily used in our tests, * &lt;a href=&quot;https://openjdk.java.net/jeps/361&quot;&gt;switch expressions&lt;/a&gt;, and more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Pretty sweet, right?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Setting different byte code levels for code and tests is pretty easy with Maven, you just need to set the following properties:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;maven.compiler.release&amp;gt;&lt;/span&gt;11&lt;span class=&quot;tag&quot;&gt;&amp;lt;/maven.compiler.release&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;maven.compiler.testRelease&amp;gt;&lt;/span&gt;17&lt;span class=&quot;tag&quot;&gt;&amp;lt;/maven.compiler.testRelease&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please note that we&amp;#8217;re using the &lt;code&gt;release&lt;/code&gt; option instead of the legacy &lt;code&gt;source&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; options, which prevents the accidental usage of Java APIs not present in the targeted Java version. See e.g. Gunnar&amp;#8217;s blog post &lt;a href=&quot;https://www.morling.dev/blog/bytebuffer-and-the-dreaded-nosuchmethoderror/&quot;&gt;ByteBuffer and the Dreaded NoSuchMethodError&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After switching to Java 11, the &lt;a href=&quot;https://maven.apache.org/plugins/maven-checkstyle-plugin/&quot;&gt;Maven Checkstyle plug-in&lt;/a&gt; and the &lt;a href=&quot;https://code.revelc.net/impsort-maven-plugin/&quot;&gt;ImpSort plug-in&lt;/a&gt; (a plug-in which takes care of proper import ordering) started to fail. However, bumping their versions to the latest releases has solved all the issues.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This was the easy part. The most difficult part was the Debezium &lt;a href=&quot;/documentation/reference/stable/connectors/cassandra.html&quot;&gt;connector for Apache Cassandra&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra_connector_tests&quot;&gt;Cassandra Connector Tests&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since &lt;a href=&quot;/blog/2022/04/06/debezium-1.9-final-released/&quot;&gt;version 1.9&lt;/a&gt;, the Cassandra connector provides support for Cassandra 3 as well as for Cassandra 4. Cassandra 4 &lt;a href=&quot;https://cassandra.apache.org/doc/4.0/cassandra/new/java11.html&quot;&gt;works like a charm with Java 11&lt;/a&gt;, but running Cassandra 3 with Java 11 is not possible (or at least requires some hacking). The existing test implementation for this connector didn&amp;#8217;t run Cassandra in a container as we do it in tests for all other DB connectors, but instead runs Cassandra in embedded mode, i.e. within the same JVM and process as the tests themselves. Therefore if you wanted to run the tests with Java 11 (or 17), tests for the Cassandra 3 connector module would fail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The obvious solution is to run Cassandra in a container with Java 8. This sounds good, but this approach has one pitfall. The Cassandra connector needs access to Cassandra log files as it obtains CDC events from them, so the tests need to access Cassandra files in the container. This can be solved quite easily using a temporary directory, for instance within the &lt;code&gt;target&lt;/code&gt; directory, mounting it as a volume into the container running Cassandra. Cassandra running in the container can later on use this mounted volume for storing its data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The real issue starts when you try to do the cleanup after the tests. As Cassandra runs in the container under a dedicated user named &lt;code&gt;cassandra&lt;/code&gt;, which is very likely not present on the test machine (or with a different UID/GID), cleanup fails when it tries to delete the temporary directory with Cassandra files. These files were created in that temporal directory mounted into the container and not in Docker FS overlay, so that are present in the &lt;code&gt;target&lt;/code&gt; directory. As the files were created by the &lt;code&gt;cassandra&lt;/code&gt; user, which is very likely different user than one who runs the tests, user running the tests has insufficient rights to delete files created by &lt;code&gt;cassandra&lt;/code&gt; user. Trying to delete them from Cassandra&amp;#8217;s container on Cassandra exit in some wrapper script turned out to be quite cumbersome and not very reliable.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The most promising solution proved to involve starting a second container with the same &lt;code&gt;cassandra&lt;/code&gt; user with access to the mounted volume and cleaning up the files after the first Cassandra container had already stopped.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We considered two options for running containers:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://dmp.fabric8.io/&quot;&gt;Fabric8 Docker Maven plugin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.testcontainers.org/&quot;&gt;Testcontainers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We use the Fabric8 plugin in the rest of the project, which suggests to use it also in this case to have uniformity across the project. On the other hand, using Testcontainers would make tests more convenient for the developers (who actually use tests after all!), as it allows to run the tests directly from IDE without starting the container manually.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the end, the decision was driven by the fact that running a cleanup container is not possible with the Fabric8 plugin. Maven doesn&amp;#8217;t allow to execute different configurations in the same phase and therefore it&amp;#8217;s not possible to stop the Cassandra container in the &lt;code&gt;post-integration-test&lt;/code&gt; phase and at the same time run a cleanup container in this phase. Testcontainers allow starting and stopping containers programmatically when needed, letting us define the images directly in the test code so we don&amp;#8217;t need any additional &lt;code&gt;Dockerfile&lt;/code&gt; , and cleaning up the container is just an implementation detail hidden in the test itself. Having the ability to run the tests directly from an IDE, without having to manually start and stop a container with the database, is a nice benefit on top of these things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The only tricky thing when using Testcontainers was that when we tried to remove the log files using Docker&amp;#8217;s &lt;code&gt;cmd&lt;/code&gt; command, Testcontainers randomly failed, stating that the container didn&amp;#8217;t start in spite of the fact that all Cassandra files were actually deleted. The container probably ran so fast that it finished before Testcontainers noticed it. Finally, we solved it by adding a short &lt;code&gt;sleep&lt;/code&gt; in the container and executing an additional command in the container which does the cleanup.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The final cleanup code using Testcontainers looks like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;@AfterClass public static void tearDownClass() throws IOException, InterruptedException { destroyTestKeyspace(); cassandra.stop(); GenericContainer cleanup = new GenericContainer(new ImageFromDockerfile() .withDockerfileFromBuilder(builder -&lt;span class=&quot;error&quot;&gt;&amp;gt;&lt;/span&gt; builder .from(&amp;quot;eclipse-temurin:8-jre-focal&amp;quot;) .volume(&amp;quot;/var/lib/cassandra&amp;quot;) .cmd(&amp;quot;sleep&amp;quot;, &amp;quot;10&amp;quot;) // Give TC some time to find out container is running. .build())) .withFileSystemBind(cassandraDir, CASSANDRA_SERVER_DIR, BindMode.READ_WRITE); cleanup.start(); cleanup.execInContainer( &amp;quot;rm&amp;quot;, &amp;quot;-rf&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/data&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/cdc_raw_directory&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/commitlog&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/hints&amp;quot;, CASSANDRA_SERVER_DIR + &amp;quot;/saved_caches&amp;quot;); cleanup.stop(); }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Once we solved the issue with the Cassandra tests, we were mostly done and were ready to use Java 11 in the main Debezium code and Java 17 for our tests.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;open_issues&quot;&gt;Open Issues&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We need more battle testing to be sure that everything works well with Java 11/17. Your help with testing and bug reports would be very valuable here and more than welcome. Currently we are aware of one minor unsolved issue related to the Java update. Some IDEs cannot distinguish between &lt;code&gt;maven.compiler.release&lt;/code&gt; and &lt;code&gt;maven.compiler.testRelease&lt;/code&gt; (or it&amp;#8217;s not very clear to us how to set it up). For example this test using a &lt;a href=&quot;https://openjdk.java.net/jeps/378&quot;&gt;text block&lt;/a&gt; is marked as an error in the IDE:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-05-04-switch-to-java-11/idea_error.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Test using text block in IntelliJ Idea.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can manually set the Java level to 17, but in this case you may unintentionally use Java &amp;gt; 11 features in non-test code without the IDE letting you know (which admittedly isn&amp;#8217;t too much of a problem, as the next Maven build, e.g. on CI, would catch that issue). Moreover, e.g. Idea resets the code level upon any changes in the &lt;code&gt;pom.xml&lt;/code&gt; files. Have you solved this issue? Or do you use an IDE which doesn&amp;#8217;t have issues with mixing different Java levels? Please share your experiences in the discussion!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Vojtěch Juránek</name></author><category term="community"/><category term="news"/><summary type="html">As you probably noticed, we have started work on Debezium 2.0. One of the planned changes for the 2.0 release is to switch to Java 11 as a baseline. While some Java build providers still support Java 8, other Java 8 distributions already reached their end of life/support. Users are moving to Java 11 anyways, as surveys like New Relic&amp;#8217;s State of the Java Ecosystem Report indicate. But it is not only matter of support: Java 11 comes with various performance improvements, useful tools like JDK Flight Recorder, which was open-sourced in Java 11, and more. So we felt it was about time to start thinking about using a more recent JDK as the baseline for Debezium, and the new major release is a natural milestone when to do the switch.</summary></entry><entry><title type="html">Debezium 2.0.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released/" rel="alternate" type="text/html" title="Debezium 2.0.0.Alpha1 Released"/><published>2022-04-28T00:00:00+00:00</published><updated>2022-04-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/28/debezium-2.0-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am excited to share that Debezium &lt;strong&gt;2.0.0.Alpha1&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is the first of several planned pre-releases of Debezium 2.0 over the next five months. Each pre-release plans to focus on strategic changes in the hope that as we move forward, changes can be easily tested and regressions addressed quickly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this release, some of the most notable changes include requiring Java 11 to use Debezium or any of its components, the removal of &lt;code&gt;wal2json&lt;/code&gt; support for PostgreSQL and the legacy MySQL connector implementation, as well as some notable features such as improved Debezium Server Google Pub/Sub sink support, and a multitude of bugfixes. Let&amp;#8217;s take a look at a few of these.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;java_11_required&quot;&gt;Java 11 required&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have wanted to make the jump to using Java 11 as a build requirement for quite some time now, and with Debezium 2.0 this is now possible. With Java 11, this enables us to take advantage of new language features, such as the new &lt;code&gt;String&lt;/code&gt; API and &lt;code&gt;Predicate&lt;/code&gt; support changes in the codebase, while also benefiting from many Java performance improvements.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our very own Vojtech Juranek will be publishing a blog post next week that discusses the switch to Java 11 and 17 in greater detail. I highly recommend giving it a read as it provides a deep dive into the technical background &amp;amp; effort that went into making this possible.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So before migrating to Debezium 2.0, be sure that Java 11 is available.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;postgresql_wal2json_support_removed&quot;&gt;PostgreSQL wal2json support removed&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The PostgreSQL connector has supported several plugins throughout Debezium 1.x, including &lt;code&gt;decoderbufs&lt;/code&gt;, &lt;code&gt;wal2json&lt;/code&gt;, and &lt;code&gt;pgoutput&lt;/code&gt;. PostgreSQL 9.6 recently reached &lt;a href=&quot;https://www.postgresql.org/support/versioning/&quot;&gt;end of life&lt;/a&gt; on November 11, 2021. This presented a great opportunity for us to review the supported decoders and to see whether we could streamline those options.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Since &lt;code&gt;pgoutput&lt;/code&gt; is a native decoder supported by all non-EOL versions of PostgreSQL (PG10+), it made sense to remove &lt;code&gt;wal2json&lt;/code&gt;. Reducing the number of decoders to 2 (down from 3), allows us to streamline the code for PostgreSQL, reduces the overall maintenance cost of the connector, and gives us a much more narrow target for overall support.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are still using PostgreSQL 9.6 or were using &lt;code&gt;wal2json&lt;/code&gt; previously, you will need to migrate to at least PostgreSQL 10.0 or to &lt;code&gt;decoderbufs&lt;/code&gt; or &lt;code&gt;pgougput&lt;/code&gt; respectively before upgrading to Debezium 2.0.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;legacy_mysql_implementation_removed&quot;&gt;Legacy MySQL implementation removed&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As some of you may or may not know, we implemented the MySQL connector based on the common-connector framework back in Debezium 1.5 (Feb 2021). As a part of that re-write, we introduced the ability for MySQL users to enable the legacy connector behavior using the configuration option &lt;code&gt;internal.implementation&lt;/code&gt; set as &lt;code&gt;legacy&lt;/code&gt;. This legacy implementation was deprecated in favor of the new common-connector framework behavior. With Debezium 2.0, this &lt;code&gt;internal.implementation&lt;/code&gt; configuration option and the legacy connector implementation have been removed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If your current connector deployment relies on this legacy implementation, you should be aware that by upgrading to Debezium 2.0, the connector will no longer use that older implementation and will use the common-connector implementation only. Feature-wise, both implementations are on-par with one another with one exception: the legacy implementation had experimental support for changing filter configurations. If you have relied on this legacy behavior, be aware that feature is no longer available.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_improvements&quot;&gt;Other fixes &amp;amp; improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There are several bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Implement Pub/Sub Lite change consumer &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4450&quot;&gt;DBZ-4450&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add Google Pub/Sub emulator support &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4491&quot;&gt;DBZ-4491&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Making Postgres &lt;code&gt;PSQLException: This connection has been closed.&lt;/code&gt; retriable &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4948&quot;&gt;DBZ-4948&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Should store event header timestamp in HistoryRecord &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4998&quot;&gt;DBZ-4998&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Getting java.sql.SQLException: ORA-01291: missing logfile while running with archive log only &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4879&quot;&gt;DBZ-4879&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Debezium uses wrong LCR format for Oracle 12.1 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4932&quot;&gt;DBZ-4932&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;NPE caused by io.debezium.connector.oracle.antlr.listener.ColumnDefinitionParserListener.resolveColumnDataType &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4976&quot;&gt;DBZ-4976&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outbox Transform does not allow expanded payload with additional fields in the envelope &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4989&quot;&gt;DBZ-4989&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CLOB with single quotes causes parser exception &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4994&quot;&gt;DBZ-4994&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cassandra 3 handler does not process partition deletions correctly &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5022&quot;&gt;DBZ-5022&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;SQL Server in multi-partition mode fails if a new database is added to an existing configuration &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5033&quot;&gt;DBZ-5033&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Quarkus 2.8.2.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5062&quot;&gt;DBZ-5062&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%202.0.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;55 issues&lt;/a&gt; were fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: Wang Min Chao, &lt;a href=&quot;https://github.com/jchipmunk&quot;&gt;Andrey Pustovetov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bmorganpa&quot;&gt;Brad Morgan&lt;/a&gt;, &lt;a href=&quot;https://github.com/calinilie&quot;&gt;Calin Laurentiu Ilie&lt;/a&gt;, &lt;a href=&quot;https://github.com/chadthman&quot;&gt;Chad Marmon&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/domsj&quot;&gt;Jan Doms&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/LarsWerkman&quot;&gt;Lars Werkman&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/yzia2000&quot;&gt;Mohammad Yousuf Minhaj Zia&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/ypt&quot;&gt;Paul Tzen&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have resolved the runtime problem with Debezium Server in the 1.9.1.Final release, so you can expect a 1.9.2.Final later this week which will also address other bugfixes. You can continue to expect updates to 1.9 in the weeks that follow as bugs are reported and fixes are made to address those.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we continue our efforts on Debezium 2.0, you can expect a second pre-release in the coming weeks, sticking to our regular 3-week cadence. In this next pre-release, we plan to focus on message schema versioning/naming, connector configuration changes with new pass-thru namespaces, removal of deprecated options, as well as unifying default value handling, just to name a few on the roadmap.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And speaking of Debezium&amp;#8217;s roadmap, stay tuned as we&amp;#8217;ll have more to share about Debezium 2.0, its future releases of 2.x, all on our roadmap soon!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am excited to share that Debezium 2.0.0.Alpha1 has been released! This release is the first of several planned pre-releases of Debezium 2.0 over the next five months. Each pre-release plans to focus on strategic changes in the hope that as we move forward, changes can be easily tested and regressions addressed quickly. In this release, some of the most notable changes include requiring Java 11 to use Debezium or any of its components, the removal of wal2json support for PostgreSQL and the legacy MySQL connector implementation, as well as some notable features such as improved Debezium Server Google Pub/Sub sink support, and a multitude of bugfixes. Let&amp;#8217;s take a look at a few of these.</summary></entry><entry><title type="html">Debezium 1.9.1.Final Released</title><link href="https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.1.Final Released"/><published>2022-04-21T00:00:00+00:00</published><updated>2022-04-21T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/21/debezium-1.9.1-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.9.1.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release primarily focuses on bugfixes and stability concerns after the 1.9.0.Final release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the more critical changes addresses a problem with the Oracle connector when stopping and restarting the connector. More specifically, the last committed transaction&amp;#8217;s events would be re-emitted upon restart and should not have been (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4936&quot;&gt;DBZ-4936&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A second critical problem was that incremental snapshots were not working correctly for MongoDB. When an incremental snapshot signal was sent, a JSON parsing error was raised and should not have been (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-5015&quot;&gt;DBZ-5015&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And finally, there were numerous SQL parsing errors for both MySQL and Oracle that were also addressed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4976&quot;&gt;DBZ-4976&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4979&quot;&gt;DBZ-4979&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4980&quot;&gt;DBZ-4980&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4994&quot;&gt;DBZ-4994&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4996&quot;&gt;DBZ-4996&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We strongly recommend upgrading to 1.9.1.Final to avoid these issues as well as the other bugfixes that were included as a part of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20and%20fixVersion%20%3D%201.9.1.Final&quot;&gt;29 issues&lt;/a&gt; were fixed in this release. Please refer to the &lt;a href=&quot;/releases/1.9/release-notes/#release-1.9.1.Final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to the following individuals from the community which contributed to Debezium 1.9.1.Final: &lt;a href=&quot;https://github.com/LarsWerkman&quot;&gt; Lars Werkman&lt;/a&gt;, &lt;a href=&quot;https://github.com/jchipmunk&quot;&gt;Andrey Pustovetov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/bmorganpa&quot;&gt;Brad Morgan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/yzia2000&quot;&gt;Mohammad Yousuf Minhaj Zia&lt;/a&gt;, &lt;a href=&quot;https://github.com/ypt&quot;&gt;Paul Tzen&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, and &lt;a href=&quot;https://github.com/chadthman&quot;&gt;chadthamn&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium 1.9 release stream will remain the current long-running version for the next five months. During this time, we will continue to evaluate user reports and do micro-releases to address bugs and regressions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also in the coming week, expect to hear updates about Debezium&amp;#8217;s &lt;a href=&quot;/roadmap&quot;&gt;roadmap&lt;/a&gt; as well as a clear plan on Debezium 2.0, it&amp;#8217;s preview releases and what lies ahead for the future. We have a lot in store to share, so be sure to stay tuned!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.9.1.Final! This release primarily focuses on bugfixes and stability concerns after the 1.9.0.Final release.</summary></entry><entry><title type="html">Read-only Incremental Snapshots for MySQL</title><link href="https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots/" rel="alternate" type="text/html" title="Read-only Incremental Snapshots for MySQL"/><published>2022-04-07T00:00:00+00:00</published><updated>2022-04-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots</id><content type="html" xml:base="https://debezium.io/blog/2022/04/07/read-only-incremental-snapshots/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The engineering team at Shopify recently improved the Debezium MySQL connector so that it supports incremental snapshotting for databases without write access by the connector, which is required when pointing Debezium to read-only replicas. In addition, the Debezium MySQL connector now also allows schema changes during an incremental snapshot. This blog post explains the implementation details of those features.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;why_read_only&quot;&gt;Why read-only?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium added the &lt;a href=&quot;/documentation/reference/stable/connectors/mysql.html#mysql-incremental-snapshots&quot;&gt;incremental snapshotting feature&lt;/a&gt; in the 1.6 release, after Netflix had announced &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;their change data capture framework&lt;/a&gt;. At Shopify, &lt;a href=&quot;https://shopify.engineering/capturing-every-change-shopify-sharded-monolith&quot;&gt;we use Debezium for change data capture (CDC)&lt;/a&gt;, and we were looking forward to being the early adopters. Besides, we wished to have a solution that is writes and locks-free.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The no writes solution allows to capture changes from read-replicas and provides the highest guarantee that CDC won&amp;#8217;t cause data corruption on the database side.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ve had to coordinate the snapshotting with migrations in the past since schema migrations blockades have affected other projects' development. The solution was to run snapshots only on weekends and as a result, we tried to snapshot as rarely as possible. We saw the opportunity to improve this part of the process as well.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This blog post dives into technical details of the read-only incremental snapshots implementation including lock-free schema changes handling during the incremental snapshot in MySQL connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshots&quot;&gt;Incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;a href=&quot;/blog/2021/10/07/incremental-snapshots/&quot;&gt;Incremental Snapshots in Debezium&lt;/a&gt; blog post covers the default implementation in detail. The algorithm utilizes a signaling table for two types of signals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;snapshot-window-open/snapshot-window-close&lt;/code&gt; as watermarks&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;execute-snapshot&lt;/code&gt; as a way to trigger an incremental snapshot&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For the read-only scenario, we needed to replace both types of signals with alternatives.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;show_master_status_for_high_and_low_watermarks&quot;&gt;SHOW MASTER STATUS for high and low watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The solution is specific to MySQL and relies on &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/replication-gtids-concepts.html&quot;&gt;global transaction identifiers (GTIDs)&lt;/a&gt;. Therefore, you need to set &lt;code&gt;gtid_mode&lt;/code&gt; to &lt;code&gt;ON&lt;/code&gt; and configure the database to preserve GTID ordering if you&amp;#8217;re reading from the read replica.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Prerequisites:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;gtid_mode = ON enforce_gtid_consistency = ON if replica_parallel_workers &amp;gt; 0 set replica_preserve_commit_order = ON&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm runs a &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/show-master-status.html&quot;&gt;SHOW MASTER STATUS&lt;/a&gt; query to get the executed GTID set before and after the chunk selection:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;low watermark = executed_gtid_set high watermark = executed_gtid_set - low watermark&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the read-only implementation, the watermarks have a form of GTID sets, e.g. like this: &lt;code&gt;2174B383-5441-11E8-B90A-C80AA9429562:1-3, 24DA167-0C0C-11E8-8442-00059A3C7B00:1-19&lt;/code&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Such watermarks do not appear in the binlog stream. Instead, the algorithm compares each event&amp;#8217;s GTID against the in-memory watermarks. The implementation ensures there are no stale reads and that a chunk only has changes that are not older than events up to low watermark.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;deduplication_algorithm_with_read_only_watermarks&quot;&gt;Deduplication algorithm with read-only watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In pseudo-code, the algorithm for deduplicating events read from the binlog and events retrieved via snapshot chunks looks like this:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt; (1) pause log event processing (2) GtidSet lwGtidSet := executed_gtid_set from SHOW MASTER STATUS (3) chunk := select next chunk from table (4) GtidSet hwGtidSet := executed_gtid_set from SHOW MASTER STATUS subtracted by lwGtidSet (5) resume log event processing inwindow := false // other steps of event processing loop while true do e := next event from changelog append e to outputbuffer if not inwindow then if not lwGtidSet.contains(e.gtid) //reached the low watermark inwindow := true else if hwGtidSet.contains(e.gtid) //haven't reached the high watermark yet if chunk contains e.key then remove e.key from chunk else //reached the high watermark for each row in chunk do append row to outputbuffer // other steps of event processing loop&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;watermark_checks&quot;&gt;Watermark checks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A database transaction can change several rows. In this case, multiple binlog events will have the same GTID. Due to GTIDs not being unique, it affects the logic of computing a chunk selection window. An event updates a window state when the watermark&amp;#8217;s GTID set doesn&amp;#8217;t contain its GTID. After the events like transaction completion and heartbeat, there won&amp;#8217;t be any further binlog events with the same GTID. For those events, it&amp;#8217;s enough to reach the watermark&amp;#8217;s upper bound to trigger a window open/close.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/window.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. A chunk selection window&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The deduplication happens within the chunk selection window as in the default implementation. Finally, the algorithm inserts a deduplicated chunk right after the high watermark:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/deduplication.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. A chunk deduplication&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_updates_for_included_tables&quot;&gt;No updates for included tables&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s crucial to receive binlog events for the snapshot to make progress. So the algorithm checks GTIDs of &lt;em&gt;all&lt;/em&gt; the events together with not included tables.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_binlog_events&quot;&gt;No binlog events&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MySQL server sends a heartbeat event after the replication connection was idle for x-seconds. The read-only implementation utilizes heartbeats when the rate of binlog updates is low.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The heartbeat has the same GTID as the latest binlog event. Thus, for a heartbeat, it&amp;#8217;s enough to reach the upper bound of the high watermark.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm uses the &lt;code&gt;server_uuid&lt;/code&gt; part of a heartbeat&amp;#8217;s GTID to get the max transaction id from the high watermark. The implementation makes sure the high watermark contains a single &lt;code&gt;server_uuid&lt;/code&gt;. An unchanged &lt;code&gt;server_uuid&lt;/code&gt; allows to avoid the scenario when the window is closed too early by a heartbeat. See the image below as an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/heartbeat.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 3. A scenario when the window would have been closed too early by a heartbeat&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat comparison against the low watermark isn&amp;#8217;t needed since it doesn&amp;#8217;t matter if the window was open or not. This simplifies the checks when there are no new events between the high and low watermarks.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;no_changes_between_watermarks&quot;&gt;No changes between watermarks&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A binlog event can open and close a window right away when there were no binlog events during the chunk selection. In this case, a high watermark will be an empty set. In this case, the snapshot chunk gets inserted right after the low watermark without deduplication.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/empty_window.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 4. An empty chunk selection window&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_topic_based_signals&quot;&gt;Kafka topic based signals&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium supports ad-hoc incremental snapshots triggered via inserts to the signaling table. A read-only alternative is to send signals through a specific Kafka topic. The format of the message mimics the signaling table structure. An execute-snapshot Kafka message includes the parameters&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;data-collections&lt;/code&gt; - list of tables to be captured&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;type&lt;/code&gt; - set to INCREMENTAL&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;Key: dbserver1 Value: {&amp;quot;type&amp;quot;:&amp;quot;execute-snapshot&amp;quot;,&amp;quot;data&amp;quot;: {&amp;quot;data-collections&amp;quot;: [&amp;quot;inventory.orders&amp;quot;], &amp;quot;type&amp;quot;: &amp;quot;INCREMENTAL&amp;quot;}}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The MySQL connector&amp;#8217;s config has a new &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mysql.html#mysql-property-signal-kafka-topic&quot;&gt;&lt;code&gt;signal.kafka.topic&lt;/code&gt;&lt;/a&gt; property. The topic has to have one partition and the delete retention policy.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A separate thread retrieves the signal messages from the Kafka topic. The key of the Kafka message needs to match the connector&amp;#8217;s name as set in &lt;code&gt;database.server.name&lt;/code&gt;. The connector will skip events that don&amp;#8217;t correspond to the connector&amp;#8217;s name with a log entry. The message key check allows reusing a signal topic for multiple connectors.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The connector&amp;#8217;s offsets include incremental snapshot context when an incremental snapshot is running. The read-only implementation adds the Kafka signal offset to the incremental snapshot context. Keeping track of the offset allows it not to miss or double process the signal when the connector restarts.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, it&amp;#8217;s not required to use Kafka to execute a read-only incremental snapshot and the default &lt;code&gt;execute-snapshot&lt;/code&gt; signal written into a signaling table will also work. Going forward, a REST API for triggering ad-hoc incremental snapshots may be envisioned as well, either exposed through Debezium Server, or as an additional REST resource deployed to Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;schema_changes_during_incremental_snapshots&quot;&gt;Schema changes during incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium MySQL connector &lt;a href=&quot;/documentation/reference/stable/connectors/mysql.html#mysql-property-incremental-snapshot-allow-schema-changes&quot;&gt;allows schema changes during an incremental snapshot&lt;/a&gt;. The connector will detect schema change during an incremental snapshot and re-select a current chunk to avoid locking DDLs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Note that changes to a primary key are not supported and can cause incorrect results if performed during an incremental snapshot.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Historized Debezium connectors like the MySQL one parse Data Definition Language (DDL) events such as &lt;code&gt;ALTER TABLE&lt;/code&gt; from the binlog stream. Connectors keep an in-memory representation of each table&amp;#8217;s schema and use those schemas to produce the appropriate change events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The incremental snapshot implementation uses binlog schema twice:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;at the moment of the chunk selection from the database&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;at the moment of the chunk insertion to the binlog stream&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The chunk&amp;#8217;s schema has to match the binlog schema at both times. Let&amp;#8217;s explore how the algorithm achieves matching schemas in detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;matching_chunk_and_binlog_schema_on_selection&quot;&gt;Matching chunk and binlog schema on selection&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When the incremental snapshot queries a database, the rows have the table&amp;#8217;s latest schema. If the binlog stream is behind, the in-memory schema may be different from the latest schema. The solution is to wait for the connector to receive the DDL event in the binlog stream. After that, the connector can use the cached table&amp;#8217;s structure to produce the correct incremental snapshot events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A snapshot chunk is selected using the JDBC API. &lt;a href=&quot;https://docs.oracle.com/en/java/javase/17/docs/api/java.sql/java/sql/ResultSetMetaData.html&quot;&gt;ResultSetMetaData&lt;/a&gt; stores the chunk&amp;#8217;s schema. The challenge is that the schema from ResultSetMetaData and the schema from binlog DDL have different formats, making it hard to determine if they are identical.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm uses two steps to obtain the matching ResultSet-based and DDL-based schemas. First, the connector queries a table&amp;#8217;s schema between low and high watermarks. As soon as the connector detects the window closure, the binlog schema is up to date with the ResultSetMetaData. After that, the connector queries the database to verify that the schema remains the same. If the schema has changed, then the connector repeats the process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The algorithm keeps the matching ResultSet and binlog schemas in memory to allow the connector to compare each chunk&amp;#8217;s schema against the cached ResultSet schema.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a chunk&amp;#8217;s schema doesn&amp;#8217;t match the cached ResultSet schema, the connector drops the selected chunk. Then the algorithm repeats the verification process of matching ResultSet and binlog schemas. After that, the connector re-selects the same chunk from the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/schema_change.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 5. Binlog schema doesn&amp;#8217;t match chunk schema on chunk selection&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;matching_chunk_and_binlog_schema_on_insertion&quot;&gt;Matching chunk and binlog schema on insertion&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A DDL event also triggers a chunk re-read for the affected table. A re-read prevents a scenario when a chunk has an older schema than the binlog stream has by the window closure. For example, the picture below illustrates the chunk selection that happened before the schema change:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2022-04-07-read-only-incremental-snapshots/ddl.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 6. Binlog schema doesn&amp;#8217;t match chunk schema on chunk insertion&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will use the standard &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial&quot;&gt;tutorial deployment&lt;/a&gt; to demonstrate read-only ad-hoc incremental snapshotting. We are using &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#using-mysql&quot;&gt;MySQL&lt;/a&gt; as the source database. For this demo, you will need to open multiple terminal windows.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the beginning we will start the deployment, create the signaling Kafka topic, and start the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 1 - start the deployment # Start the deployment export DEBEZIUM_VERSION=1.9 docker-compose -f docker-compose-mysql.yaml up # Terminal 2 # Enable enforce_gtid_consistency and gtid_mode docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'mysql -p$MYSQL_ROOT_PASSWORD inventory -e &amp;quot;SET GLOBAL enforce_gtid_consistency=ON; SET GLOBAL gtid_mode=OFF_PERMISSIVE; SET GLOBAL gtid_mode=ON_PERMISSIVE; SET GLOBAL gtid_mode=ON;&amp;quot;' # Confirm the changes docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'mysql -p$MYSQL_ROOT_PASSWORD inventory -e &amp;quot;show global variables like \&amp;quot;%GTID%\&amp;quot;;&amp;quot;' # Create a signaling topic docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-topics.sh \ --create \ --bootstrap-server kafka:9092 \ --partitions 1 \ --replication-factor 1 \ --topic dbz-signals # Start MySQL connector, capture only customers table and enable signaling curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; -H &amp;quot;Content-Type:application/json&amp;quot; http://localhost:8083/connectors/ -d @- &amp;lt;&amp;lt;EOF { &amp;quot;name&amp;quot;: &amp;quot;inventory-connector&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.debezium.connector.mysql.MySqlConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;database.hostname&amp;quot;: &amp;quot;mysql&amp;quot;, &amp;quot;database.port&amp;quot;: &amp;quot;3306&amp;quot;, &amp;quot;database.user&amp;quot;: &amp;quot;debezium&amp;quot;, &amp;quot;database.password&amp;quot;: &amp;quot;dbz&amp;quot;, &amp;quot;database.server.id&amp;quot;: &amp;quot;184054&amp;quot;, &amp;quot;database.server.name&amp;quot;: &amp;quot;dbserver1&amp;quot;, &amp;quot;database.include.list&amp;quot;: &amp;quot;inventory&amp;quot;, &amp;quot;database.history.kafka.bootstrap.servers&amp;quot;: &amp;quot;kafka:9092&amp;quot;, &amp;quot;database.history.kafka.topic&amp;quot;: &amp;quot;schema-changes.inventory&amp;quot;, &amp;quot;table.include.list&amp;quot;: &amp;quot;inventory.customers&amp;quot;, &amp;quot;read.only&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;incremental.snapshot.allow.schema.changes&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;incremental.snapshot.chunk.size&amp;quot;: &amp;quot;5000&amp;quot;, &amp;quot;signal.kafka.topic&amp;quot;: &amp;quot;dbz-signals&amp;quot;, &amp;quot;signal.kafka.bootstrap.servers&amp;quot;: &amp;quot;kafka:9092&amp;quot; } } EOF&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the log we see that as per the &lt;code&gt;table.include.list&lt;/code&gt; setting only one table is snapshotted, &lt;code&gt;customers&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;tutorial-connect-1 | 2022-02-21 04:30:03,936 INFO MySQL|dbserver1|snapshot Snapshotting contents of 1 tables while still in transaction [io.debezium.relational.RelationalSnapshotChangeEventSource]&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next step we will simulate continuous activity in the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 3 # Continuously consume messages from Debezium topic for customers table docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.customers # Terminal 4 # Modify records in the database via MySQL client docker-compose -f docker-compose-mysql.yaml exec mysql bash -c 'i=0; while true; do mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory -e &amp;quot;INSERT INTO customers VALUES(default, \&amp;quot;name$i\&amp;quot;, \&amp;quot;surname$i\&amp;quot;, \&amp;quot;email$i\&amp;quot;);&amp;quot;; ((i++)); done'&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic &lt;code&gt;dbserver1.inventory.customers&lt;/code&gt; receives a continuous stream of messages. Now the connector will be reconfigured to also capture the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;# Terminal 5 # Add orders table among the captured curl -i -X PUT -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/inventory-connector/config -d @- &amp;lt;&amp;lt;EOF { &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;, &quot;tasks.max&quot;: &quot;1&quot;, &quot;database.hostname&quot;: &quot;mysql&quot;, &quot;database.port&quot;: &quot;3306&quot;, &quot;database.user&quot;: &quot;debezium&quot;, &quot;database.password&quot;: &quot;dbz&quot;, &quot;database.server.id&quot;: &quot;184054&quot;, &quot;database.server.name&quot;: &quot;dbserver1&quot;, &quot;database.include.list&quot;: &quot;inventory&quot;, &quot;database.history.kafka.bootstrap.servers&quot;: &quot;kafka:9092&quot;, &quot;database.history.kafka.topic&quot;: &quot;schema-changes.inventory&quot;, &quot;table.include.list&quot;: &quot;inventory.customers,inventory.orders&quot;, &quot;read.only&quot;: &quot;true&quot;, &quot;incremental.snapshot.allow.schema.changes&quot;: &quot;true&quot;, &quot;incremental.snapshot.chunk.size&quot;: &quot;5000&quot;, &quot;signal.kafka.topic&quot;: &quot;dbz-signals&quot;, &quot;signal.kafka.bootstrap.servers&quot;: &quot;kafka:9092&quot; } EOF&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As expected, there are no messages for the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now let&amp;#8217;s start an incremental ad-hoc snapshot by sending a signal. The snapshot messages for the &lt;code&gt;orders&lt;/code&gt; table are delivered to the &lt;code&gt;dbserver1.inventory.orders&lt;/code&gt; topic. Messages for the &lt;code&gt;customers&lt;/code&gt; table are delivered without interruption.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 # Send the signal docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-producer.sh \ --broker-list kafka:9092 \ --property &amp;quot;parse.key=true&amp;quot; \ --property &amp;quot;key.serializer=org.apache.kafka.common.serialization.StringSerializer&amp;quot; \ --property &amp;quot;value.serializer=custom.class.serialization.JsonSerializer&amp;quot; \ --property &amp;quot;key.separator=;&amp;quot; \ --topic dbz-signals dbserver1;{&amp;quot;type&amp;quot;:&amp;quot;execute-snapshot&amp;quot;,&amp;quot;data&amp;quot;: {&amp;quot;data-collections&amp;quot;: [&amp;quot;inventory.orders&amp;quot;], &amp;quot;type&amp;quot;: &amp;quot;INCREMENTAL&amp;quot;}} # Check messages for orders table docker-compose -f docker-compose-mysql.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you were to modify any record in the &lt;code&gt;orders&lt;/code&gt; table while the snapshot is running, this would be either emitted as a &lt;code&gt;read&lt;/code&gt; event or as an &lt;code&gt;update&lt;/code&gt; event, depending on the exact timing and sequence of things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the last step, let&amp;#8217;s terminate the deployed systems and close all terminals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Shut down the cluster docker-compose -f docker-compose-mysql.yaml down&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is an excellent change data capture tool under active development, and it&amp;#8217;s a pleasure to be a part of its community. We&amp;#8217;re excited to use incremental snapshots in production here at Shopify. If you have similar database usage restrictions, check out the read-only incremental snapshots feature. Many thanks to my team and the Debezium team without whom this project wouldn&amp;#8217;t happen.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Kate Galieva</name></author><category term="mysql"/><category term="snapshots"/><summary type="html">The engineering team at Shopify recently improved the Debezium MySQL connector so that it supports incremental snapshotting for databases without write access by the connector, which is required when pointing Debezium to read-only replicas. In addition, the Debezium MySQL connector now also allows schema changes during an incremental snapshot. This blog post explains the implementation details of those features.</summary></entry><entry><title type="html">Debezium 1.9.0.Final Released</title><link href="https://debezium.io/blog/2022/04/06/debezium-1.9-final-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Final Released"/><published>2022-04-06T00:00:00+00:00</published><updated>2022-04-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/04/06/debezium-1.9-final-released</id><content type="html" xml:base="https://debezium.io/blog/2022/04/06/debezium-1.9-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am very happy to share the news that Debezium &lt;strong&gt;1.9.0.Final&lt;/strong&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides the usual set of bug fixes and improvements, key features of this release are support for Apache Cassandra 4, multi-database support for the Debezium connector for SQL Server, the ability to use Debezium Server as a Knative event source, as well as many improvements to the integration of Debezium Server with Redis Streams.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Exactly &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.9.0.Alpha1%2C%201.9.0.Alpha2%2C%201.9.0.Beta1%2C%201.9.0.CR1%2C%201.9.0.Final)%20ORDER%20BY%20key%20ASC%2C%20status%20DESC&quot;&gt;276 issues&lt;/a&gt; have been fixed by the community for the 1.9 release; a big thank you to each and everyone who helped to make this happen!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_apache_cassandra_4&quot;&gt;Support for Apache Cassandra 4&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Added right in time for the &lt;a href=&quot;/blog/2022/03/25/debezium-1-9-cr1-released/&quot;&gt;candidate release&lt;/a&gt; of Debezium 1.9, support for Cassandra 4 has been added to the &lt;a href=&quot;/documentation/reference/1.9/connectors/cassandra.html&quot;&gt;Debezium Cassandra connector&lt;/a&gt;. Or, more specifically, a &lt;em&gt;new&lt;/em&gt; connector has been added. I.e. you should now either download the &lt;em&gt;debezium-connector-cassandra-3&lt;/em&gt; or the &lt;em&gt;debezium-connector-cassandra-4&lt;/em&gt; connector archive, depending on your database version. While we usually strive for multi-version support within indvidual connectors, the code changes required to support the new version were that substantial, that we decided to have two separate code bases for the two connector versions (with commonalities extracted into a shared module).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Both connectors, for Cassandra 3 and 4, remain in incubating state for the time being and you can expect further improvements to them within the near feature. A massive thank you to &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Štefan Miklošovič&lt;/a&gt; and &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt; for this huge piece of work, which also paves the road towards moving to Java 11 as the baseline for Debezium in the near future.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;sql_server_multi_database_support&quot;&gt;SQL Server Multi-Database Support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;SQL Server allows for setting up multiple logical databases on one physical host, which for instance comes in handy for separating the data of different tenants of a multi-tenant capable application. Historically, this required to set up one instance of the Debezium connector for SQL Server per logical database, which could become a bit cumbersome when dealing with tens or even hundreds of databases, as often the case for multi-tenancy use cases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Over the last year, &lt;a href=&quot;/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/&quot;&gt;Sergei Morozov&lt;/a&gt; and his team at SugarCRM reworked the &lt;a href=&quot;/documentation/reference/stable/connectors/sqlserver.html&quot;&gt;Debezium SQL Server connector&lt;/a&gt; and the Debezium connector framework to be &lt;em&gt;multi-partition aware&lt;/em&gt; for address sitations like this: the framework is now capable of streaming changes from multiple &lt;em&gt;source partitions&lt;/em&gt;, which are split up between &lt;em&gt;connector tasks&lt;/em&gt; (in Kafka Connect terminology), which in turn can be distributed amongst the worker nodes of a Kafka Connect cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In case of the SQL Server connector, a logical database equates to one such source partition, so that you now can stream for instance 20 databases from one physical SQL Server host, spread across four source tasks running on five Kafka Connect worker nodes. To use the new multi-partition mode, configure the names of the databases to capture via the new &lt;a href=&quot;/documentation/reference/stable/connectors/sqlserver.html#sqlserver-property-database-names&quot;&gt;&lt;code&gt;database.names&lt;/code&gt;&lt;/a&gt; connector configuration property (rather than using the previously existing &lt;code&gt;database.dbname&lt;/code&gt;), and optionally set the value of &lt;code&gt;tasks.max&lt;/code&gt; to a value larger than 1. Note that the schema and topic names as well as the structure of connector metrics differs between single and multi-partition mode, so as to account for the name of the logical database and the id of the source task, respectively.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/multi_partition_metrics.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Multi-partition mode is experimental as of the 1.9 release and is planned to fully replace the legacy single partition mode for the SQL Server connector in a future release, i.e. also if you&amp;#8217;d capture changes from only one single logical database, you&amp;#8217;ll be using the multi-partition mode then. Multi-partition mode will also be rolled out for other connectors where it&amp;#8217;s possible, e.g. for the connectors for Oracle and IBM Db2.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks a lot to Sergei and team for their excellent collaboration around that feature!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_changes&quot;&gt;Further Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a look at some more features new in Debezium 1.9. First, Debezium Server now includes a &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#_http_client&quot;&gt;sink adaptor for HTTP&lt;/a&gt;, which means it can be used as a &quot;native&quot; event source for Knative Serving, without the need for sending messages through a message broker like Apache Kafka first.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Then, the friendly folks over at Redis stepped up and contributed several improvements to how Debezium (Server) integrates with &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#_redis_stream&quot;&gt;Redis Streams&lt;/a&gt;: besides several performance improvements, the database history for connectors like the MySQL one can now be stored in Redis, also offsets can be stored there now. But they didn&amp;#8217;t stop there: for instance, Debezium Server now supports custom configuration providers, as already provided in Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, the Redis team is planning to work on further cool improvements to Debezium at large, such as better retrying logic in case of failures. Looking forward to those!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about all the features, improvements and bug fixes shipped in Debezium 1.9, please check out the original release announcements (&lt;a href=&quot;/blog/2022/01/26/debezium-1-9-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2022/02/09/debezium-1-9-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2022/03/03/debezium-1-9-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, and &lt;a href=&quot;/blog/2022/03/25/debezium-1-9-cr1-released/&quot;&gt;CR1&lt;/a&gt;) as well as the &lt;a href=&quot;/releases/1.9/release-notes&quot;&gt;1.9 release notes&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to all the folks from the Debezium community which contributed code changes to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/samagonas&quot;&gt;Aidas&lt;/a&gt;, &lt;a href=&quot;https://github.com/isacandrei&quot;&gt;Andrei Isac&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/sormuras&quot;&gt;Christian Stein&lt;/a&gt;, &lt;a href=&quot;https://github.com/clement-loiselet-talend&quot;&gt;Clément Loiselet&lt;/a&gt;, &lt;a href=&quot;https://github.com/daha&quot;&gt;David Haglund&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/EthanZ328&quot;&gt;Ethan Zou&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuyar&quot;&gt;Farid Uyar&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/hjwalt&quot;&gt;Hady Willi&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/jmks&quot;&gt;Jason Schweier&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis Sánchez&lt;/a&gt;, &lt;a href=&quot;https://github.com/jribera-sugarcrm&quot;&gt;Josh Ribera&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/limer2&quot;&gt;Li Mo&lt;/a&gt;, &lt;a href=&quot;https://github.com/sazzad16&quot;&gt;M Sazzadul Hoque&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/wndemon&quot;&gt;Nansen&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/nenad&quot;&gt;Nenad Stojanovikj&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/0sc&quot;&gt;Oscar Romero&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/poonam-meghnani&quot;&gt;Poonam Meghnani&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhongqishang&quot;&gt;Qishang Zhong&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarumont&quot;&gt;Richard Kolkovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sebruck&quot;&gt;Sebastian Bruckner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtěch Juránek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;, &lt;a href=&quot;https://github.com/yingyingtang-brex&quot;&gt;Yingying Tang&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, and &lt;a href=&quot;https://github.com/AChangFeng&quot;&gt;胡琴&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;coming_up&quot;&gt;Coming Up&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;So what&amp;#8217;s next after 1.9? You may think 1.10, but that&amp;#8217;s not what we&amp;#8217;ll do; instead, we&amp;#8217;re planning to release Debezium 2.0 as a new major version later this year!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While we don&amp;#8217;t strictly adhere to semantic versioning (i.e. a new minor release like 1.9 may require some small degree of consideration), one of our key objectives with Debezium releases is to limit breaking changes for existing users as much as possible. That&amp;#8217;s why for instance configuration options that became superfluous are not just removed but deprecated. The same applies for changes to the change event format, which are rolled out gradually. Over time, this has led to a number of legacy options and other aspects which we finally want to iron out. Debezium 2.0 will be the release where we will get rid of this kind of legacy cruft. For instance, we are planning to&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Remove the legacy implementations of the connectors for MySQL and MongoDB (superseded by more capable and mature implementations based on Debezium&amp;#8217;s standard connector framework, which have been enabled by default for quite some time)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Drop wal2json support for Postgres (superseded by pgoutput)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Use Java 11 as a baseline (for instance allowing to emit JDK Flight Recorder events for better diagnostics)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Default to multi-partition mode metrics (improved consistency)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Make default topic names more consistent, for instance for the heartbeat topic&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Change the default type mappings for a small number of column types&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Planning for this is in full swing right now, and you are very much invited to join the discussion either on the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; or on the &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;DBZ-3899&lt;/a&gt; issue in Jira. Note that while we want to take the opportunity to clean up some odditities which have accumulated over time, backwards compatibility will be key concern as always, and we&amp;#8217;ll try to minimize the impact on existing users. But as you would expect it from a new major release, upgrading may take a slightly larger effort in comparison to the usual minor releases.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In terms of a timeline, due to the size and number of planned changes, we&amp;#8217;re going to deviate from the usual quarterly release cadence and instead reserve two quarters for working on Debezium 2.0, i.e. you can look forward to that release at the end of September. In the meantime, there will be bugfix releases of the 1.9 version, as needed per incoming bug reports.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Upwards and onwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am very happy to share the news that Debezium 1.9.0.Final has been released! Besides the usual set of bug fixes and improvements, key features of this release are support for Apache Cassandra 4, multi-database support for the Debezium connector for SQL Server, the ability to use Debezium Server as a Knative event source, as well as many improvements to the integration of Debezium Server with Redis Streams. Exactly 276 issues have been fixed by the community for the 1.9 release; a big thank you to each and everyone who helped to make this happen!</summary></entry><entry><title type="html">Debezium 1.9.0.CR1 Released</title><link href="https://debezium.io/blog/2022/03/25/debezium-1-9-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.CR1 Released"/><published>2022-03-25T00:00:00+00:00</published><updated>2022-03-25T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/03/25/debezium-1-9-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/03/25/debezium-1-9-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am happy to announce the release of Debezium &lt;strong&gt;1.9.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides a range of bugfixes, this release brings the long-awaited support for Apache Cassandra 4! Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.CR1%20ORDER%20BY%20component%20ASC&quot;&gt;52 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at both the Cassandra 3 changes &amp;amp; Cassandra 4 support.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cassandra_3_changes_cassandra_4_support&quot;&gt;Cassandra 3 changes &amp;amp; Cassandra 4 support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;cassandra_3_breaking_changes&quot;&gt;Cassandra 3 breaking changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For users who need to use Cassandra 3, the Maven coordinates of the (incubating) connector have changed slightly in this release. The main change for Cassandra 3 is that the artifact name has changed:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;io.debezium&lt;span class=&quot;tag&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;debezium-connector-cassandra-3&lt;span class=&quot;tag&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.9.0.CR1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There is one additional user-facing change that this release introduces, which is a shift in the Cassandra driver. The connection configuration is no longer provided directly in the connector properties file but instead must be supplied using a separate &lt;code&gt;application.conf&lt;/code&gt; file. You can find a full reference on the driver&amp;#8217;s configuration &lt;a href=&quot;https://docs.datastax.com/en/developer/java-driver/4.2/manual/core/configuration/reference/&quot;&gt;here&lt;/a&gt; and below is an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;datastax-java-driver { basic { request.timeout = 20 seconds contact-points = [ &quot;spark-master-1:9042&quot; ] load-balancing-policy { local-datacenter = &quot;dc1&quot; } } advanced { auth-provider { class = PlainTextAuthProvider username = user password = pass } ssl-engine-factory { ... } } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order for the Debezium connector to read/use this new application configuration file, it must be set in the connector properties file as follows:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;cassandra.driver.config.file=/path/to/application/configuration.conf&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;cassandra_4_support&quot;&gt;Cassandra 4 support&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For new users and those looking to upgrade to Cassandra 4, the Maven coordinates for the new connector artifact are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;io.debezium&lt;span class=&quot;tag&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;debezium-connectr-cassandra-4&lt;span class=&quot;tag&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.9.0.CR1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We introduced a new artifact rather than a user configurable toggle as this allows both code bases to diverge as needed. This allows both the Cassandra 3 and 4 connectors to be refined as needed, as we move forward to building the Cassandra 4 connector with Java 11 as a baseline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium for Cassandra 4 connector is based on Apache Cassandra 4.0.2. If you intend to upgrade to Cassandra 4, the migration should be relatively seamless from Debezium&amp;#8217;s perspective. Once the Cassandra environment has been upgraded, adjust the driver configuration as outlined in the above Cassandra 3 breaking changes section and restart the connector.hanges section and start the connector.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We would like to thank &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Štefan Miklošovič&lt;/a&gt; and &lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt; for this contribution!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_and_changes&quot;&gt;Other Fixes and Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in the 1.9.0.CR1 release include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Various DDL parser fixes for both MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4786&quot;&gt;DBZ-4786&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4833&quot;&gt;DBZ-4833&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4841&quot;&gt;DBZ-4841&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4810&quot;&gt;DBZ-4810&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4851&quot;&gt;DBZ-4851&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector gracefully handles unsupported column types (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4852&quot;&gt;DBZ-4852&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4853&quot;&gt;DBZ-4853&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4880&quot;&gt;DBZ-4880&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improve Oracle connector&amp;#8217;s supplemental log checks (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4842&quot;&gt;DBZ-4842&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4869&quot;&gt;DBZ-4869&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Various MySQL connector improvements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4758&quot;&gt;DBZ-4758&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4787&quot;&gt;DBZ-4787&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.0-cr1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/clement-loiselet-talend&quot;&gt;Clément Loiselet&lt;/a&gt;, &lt;a href=&quot;https://github.com/EthanZ328&quot;&gt;Ethan Zou&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis Sánchez&lt;/a&gt;, &lt;a href=&quot;https://github.com/jribera-sugarcrm&quot;&gt;Josh Ribera&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtěch Juránek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With CR1 done, you can expect 1.9 Final either later this week or early next week depending on issue reports.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we begin to look ahead, you can expect work on Debezium 2.0 to begin in the near future. The current roadmap is to devote the next two release cycles on Debezium 2.0, releasing it sometime near the end of September 2022. In the meantime, expect regular updates to continue for Debezium 1.9 throughout this process.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am happy to announce the release of Debezium 1.9.0.CR1! Besides a range of bugfixes, this release brings the long-awaited support for Apache Cassandra 4! Overall, 52 issues have been fixed for this release. Let&amp;#8217;s take a closer look at both the Cassandra 3 changes &amp;amp; Cassandra 4 support.</summary></entry><entry><title type="html">Hello Debezium Team!</title><link href="https://debezium.io/blog/2022/03/15/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium Team!"/><published>2022-03-15T09:19:59+00:00</published><updated>2022-03-15T09:19:59+00:00</updated><id>https://debezium.io/blog/2022/03/15/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2022/03/15/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Hi everyone, my name is Vojtěch Juránek and I recently joined the Debezium team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Most of my professional IT career I&amp;#8217;ve spent at Red Hat. I have a background in particle physics, but I did quite a lot programming even before joining Red Hat, when working on &lt;a href=&quot;https://herwig.hepforge.org/&quot;&gt;simulations of high-energy particle collisions&lt;/a&gt; and their &lt;a href=&quot;https://root.cern/&quot;&gt;data analysis&lt;/a&gt;. The science is by default open and all software I was using was open source as well. Here started my love for open source.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When I decided to do programming for a living, Red Had was a natural choice for me, as by that time it was one of the few companies which promoted open source heavily. I started to work at Red Hat as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hudson_(software)&quot;&gt;Hudson&lt;/a&gt; developer. I developed and maintained many plugins and also contributed to Hudson core. I focused mainly on Hudson stability and memory footprint as I also took care about internal JBoss Hudson instance, which was the world&amp;#8217;s largest Hudson deployment by that time. When Hudson was forked to &lt;a href=&quot;https://www.jenkins.io/&quot;&gt;Jenkins&lt;/a&gt;, I co-created and a maintained Jenkins LTS (long term support) branch. I was also a member of Jenkins CERT team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After a couple of years spent with Hudson/Jenkins, I decided it&amp;#8217;s time to move on and joined &lt;a href=&quot;https://infinispan.org/&quot;&gt;Infinispan&lt;/a&gt; team as a quality engineer. Knowing only a little about things like memory data grid when I joined the team, I quickly discovered the beautiful world of distributed systems and fell in love with it. As a quality engineer on the Infinispan project I not only dug deep in distributed databases and consensus algorithms, but also became familiar with other very interesting projects like e.g. &lt;a href=&quot;https://jepsen.io/&quot;&gt;Jepsen&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Later on, I accepted the challenge to discover another interesting world - the world of virtual machines and data centers and started to work as a developer on &lt;a href=&quot;https://www.ovirt.org/&quot;&gt;oVirt project&lt;/a&gt; project in the storage team. I was mostly working on low level stuff, on projects &lt;a href=&quot;https://github.com/ovirt/vdsm&quot;&gt;vdsm&lt;/a&gt; and &lt;a href=&quot;https://github.com/oVirt/ovirt-imageio/&quot;&gt;imageio&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Working on oVirt was interesting, but I was really excited when I got an opportunity to move back to databases and distributed systems and join the Debezium project. I&amp;#8217;m looking forward to work on this wonderful project!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Onwards,&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;--Vojta&lt;/p&gt; &lt;/div&gt;</content><author><name>Vojtěch Juránek</name></author><category term="community"/><category term="news"/><summary type="html">Hi everyone, my name is Vojtěch Juránek and I recently joined the Debezium team. Most of my professional IT career I&amp;#8217;ve spent at Red Hat. I have a background in particle physics, but I did quite a lot programming even before joining Red Hat, when working on simulations of high-energy particle collisions and their data analysis. The science is by default open and all software I was using was open source as well. Here started my love for open source.</summary></entry><entry><title type="html">Debezium 1.9.0.Beta1 Released</title><link href="https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Beta1 Released"/><published>2022-03-03T00:00:00+00:00</published><updated>2022-03-03T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am happy to announce the release of Debezium &lt;strong&gt;1.9.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release includes many new features for Debezium Server, including Knative Eventing support and offset storage management with the Redis sink, multi-partitioned scaling for the SQL Server connector, and various of bugfixes and improvements. Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;56 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at a couple of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_server_knative_eventing&quot;&gt;Debezium Server Knative Eventing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium Server has grown quite a lot since its introduction to the Debezium portfolio in version 1.2. In this release, we have added a new sink implementation to support &lt;a href=&quot;https://knative.dev/docs/eventing/&quot;&gt;Knative Eventing&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Knative Eventing &quot;provides tools and infrastructure to route events from a producer to consumers&quot;, in a very similar way in which Apache Kafka allows the exchange of events via message topics. With Debezium Server, you can now leverage the new &lt;a href=&quot;https://github.com/debezium/debezium/tree/main/debezium-server/debezium-server-http&quot;&gt;debezium-server-http&lt;/a&gt; sink to deliver Debezium change data events to a Knative Broker, a Kubernetes resource that defines a mesh for collecting and distributing &lt;a href=&quot;https://cloudevents.io/&quot;&gt;CloudEvents&lt;/a&gt; to consumers. In other words, Debezium Server can act as a &quot;native&quot; Knative event source.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to get started with Debezium and Knative Eventing, you simply need to configure the Debezium Server with your desired source connector and then configure the sink side with the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.type=http debezium.format.value=cloudevents&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The sink will attempt to automatically detect the endpoint based on the &lt;code&gt;K_SINK&lt;/code&gt; environment variable. If no value is defined by this variable, you can explicitly provide the end-point URL directly using:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.http.url=https://&amp;lt;hostname&amp;gt;/&amp;lt;end-point&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re super excited about this new sink connector and we look forward to all your feedback. A big thank you to &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt; for this excellent contribution!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;redis_managed_offsets_for_debezium_server&quot;&gt;Redis-managed Offsets for Debezium Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Several folks from &lt;a href=&quot;https://redis.com/&quot;&gt;Redis&lt;/a&gt; stepped up lately for improving the story around integrating Debezium and &lt;a href=&quot;https://redis.io/topics/streams-intro&quot;&gt;Redis Streams&lt;/a&gt;. After the performance improvements done in 1.9.0.Alpha1 (by means of batching), another result of that work is the ability to &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#debezium-source-offset-storage&quot;&gt;store connector offsets&lt;/a&gt; in Redis. For the next 1.9 early access release you can expect a database history implementation backed by Redis, and the team also is working on implementing retry support for Debezium Server. Thanks a lot to &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt; and all the other Redis folks contributing not only to the Redis Streams sink, but also to Debezium and Debezium Server at large!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;multi_partitioned_scaling_for_sql_server_connector&quot;&gt;Multi-partitioned Scaling for SQL Server Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some database platforms, such as SQL Server and Oracle, support the creation and management of multiple logical databases within a single physical database server instance. Traditionally, streaming changes from the multiple logical databases required a separate connector deployment. Now there isn&amp;#8217;t anything innately wrong with such a deployment strategy, but it can quickly start to show its shortcomings if you have many logical databases; for instance in case of multi-tenancy scenarios with one logical database per tenant, the overhead of setting up and operating one connector per database can become a bottleneck. Besides that, processing change events from multiple logical databases lends itself perfectly well to parallelization by means of Kafka Connect&amp;#8217;s concept of tasks.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Over the last several 1.x releases, a tremendous amount of work has gone into key fundamental changes to Debezium&amp;#8217;s common connector framework, setting the stage for a new horizontal scaling strategy.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the initial goals of this new strategy is to eliminate the need for multiple connector deployments when streaming changes from multiple logical databases within a single SQL Server instance. Additionally, it was critical to expose metrics in a way that enables monitoring tools to report on the state and health of the connector both from a connector-centric perspective but also from each logical database being processed. In this release, we&amp;#8217;ve achieved those goals.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/multi_partition_metrics.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But this is just the beginning folks!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This foundation prepares the groundwork where we can move toward new horizontal scaling strategies. Debezium uses a single-task based architecture and this opens the possibilities to really harness the power of a multi-node Kafka Connect cluster and distribute chunks of work across multiple tasks. Furthermore, this can be extended to other connectors such as Oracle.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This work has been led by the team around &lt;a href=&quot;/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/&quot;&gt;Sergei Morozov&lt;/a&gt; of SugarCRM, who already deploy the SQL Server connector in multi-partition mode built from an internal fork, which they internally maintain until the entire work has been upstreamed. We&amp;#8217;d like to say a huge, huge thank you to Sergei, Jacob Gminder, Mike Kamornikov, and everyone else from SugarCRM who worked tirelessly to make this possible for the Debezium community, and we&amp;#8217;re looking forward very much to continuing and further expanding this close collaboration.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_and_changes&quot;&gt;Other Fixes and Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in the 1.9.0.Beta1 release include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Various DDL parser fixes for both MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4707&quot;&gt;DBZ-4707&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4641&quot;&gt;DBZ-4641&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4662&quot;&gt;DBZ-4662&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4706&quot;&gt;DBZ-4706&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4746&quot;&gt;DBZ-4746&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4746&quot;&gt;DBZ-4752&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4763&quot;&gt;DBZ-4763&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Corrected a long-running transaction issue with the PostgreSQL connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2306&quot;&gt;DBZ-2306&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector stability improvements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4635&quot;&gt;DBZ-4635&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4715&quot;&gt;DBZ-4715&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4723&quot;&gt;DBZ-4723&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4737&quot;&gt;DBZ-4737&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4744&quot;&gt;DBZ-4744&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.0-beta1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/samagonas&quot;&gt;Aidas&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/jribera-sugarcrm&quot;&gt;Josh Ribera&lt;/a&gt;, &lt;a href=&quot;https://github.com/limer2&quot;&gt;Li Mo&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/sazzad16&quot;&gt;M Sazzadul Hoque&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;, &lt;a href=&quot;https://github.com/yingyingtang-brex&quot;&gt;Yingying Tang&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the Beta1 release done, we are approaching the final phase of the 1.9 release cycle. Depending on the incoming issue reports, you can expect a new release in the next few weeks to likely be CR1.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we turn and look ahead beyond 1.9, you can expect work on Debezium 2.0 to begin in early April 2022. The current roadmap is to devote 2 full release cycles, which means you can expect Debezium 2.0 sometime near the end of September 2022. In the meantime, you can expect regular updates to Debezium 1.9 throughout this process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are interested in Debezium 2.0, we have collected a number of items in &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;DBZ-3899&lt;/a&gt; thus far. This is not an exhaustive list nor has this list been prioritized and scoped to what you can expect in totality of 2.0; however, it is what we&amp;#8217;ve identified to be things that either the community or the team feel are actionable tasks for this new major release. If there is something you would like to see, please take a moment and either raise a discussion on the above Jira ticket or join the discussion on &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;this topic&lt;/a&gt; on our mailing list.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am happy to announce the release of Debezium 1.9.0.Beta1! This release includes many new features for Debezium Server, including Knative Eventing support and offset storage management with the Redis sink, multi-partitioned scaling for the SQL Server connector, and various of bugfixes and improvements. Overall, 56 issues have been fixed for this release. Let&amp;#8217;s take a closer look at a couple of them.</summary></entry><entry><title type="html">Debezium 1.9.0.Alpha2 Released</title><link href="https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Alpha2 Released"/><published>2022-02-09T00:00:00+00:00</published><updated>2022-02-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.9 series, &lt;strong&gt;1.9.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release includes support for Oracle 21c, improvements around Redis for Debezium Server, configuring the &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt; option, and a number of bug fixes around DDL parsers, build infrastructure, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;51 issues&lt;/a&gt; for this release. Let’s take a closer look at some of the highlights.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_oracle_21c&quot;&gt;Support for Oracle 21c&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium Oracle connector has been tested with the latest release of Oracle 21c, 21.3.0.0, and is compatible. If you use either the LogMiner or the Xstreams adapter, you should now be able to use Oracle&amp;#8217;s latest flagship version and stream change events without any changes. If you are on Oracle 12 or Oracle 19 and perform a database upgrade, your connector configuration should require no changes and remain compatible.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configuring_kafka_query_timeout_ms&quot;&gt;Configuring &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt;&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the Kafka Admin Client and issuing API calls, the default timeout is 3 seconds. The new &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt; field can be used to provide a custom timeout to the Kafka Admin Client to avoid possible timeout problems in environments that may use TLS or SSL encryption or where network latency causes an unexpected timeout.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to the great work done by community member, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improvements_in_redis_for_debezium_server&quot;&gt;Improvements in Redis for Debezium Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have three new fields in the Redis support for Debezium Server&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;redis.retry.initial.delay.ms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;redis.retry.max.delay.ms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;batch.size&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Redis allows specifying a maximum memory limit using the &lt;code&gt;maxmemory&lt;/code&gt; configuration; however, if this field is not configured then Redis will continue to allocate memory. If all memory is consumed, an OutOfMemory exception occurs. The Redis sink now uses &lt;code&gt;redis.retry.initial.delay.ms&lt;/code&gt; and &lt;code&gt;redis.retry.max.delay.ms&lt;/code&gt; to set an initial and max-retry delay to be more resilient to this and connection-related issues. If you have or are experiencing such exceptions, we urge you to try these new settings to improve the sink&amp;#8217;s resilience and experience.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Pipeline-based transactions can substantially increase Redis queries. In order to leverage pipeline-based transactions, the &lt;code&gt;batch.size&lt;/code&gt; configuration option can be specified which will allow Redis to write batches of change records rather than each record one by one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to &lt;a href=&quot;https://github.com/spicy-sauc&quot;&gt;Yossi Shirizli&lt;/a&gt;, for these amazing improvements.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some notable bug fixes and upgrades are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Suspected inconsistent documentation for 'Ad-hoc read-only Incremental snapshot' &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4171&quot;&gt;DBZ-4171&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle Logminer: snapshot&amp;#8594;stream switch misses DB changes in ongoing transactions &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4367&quot;&gt;DBZ-4367&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DDL parsing issue: ALTER TABLE &amp;#8230;&amp;#8203; MODIFY PARTITION &amp;#8230;&amp;#8203; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4649&quot;&gt;DBZ-4649&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;OracleSchemaMigrationIT fails with Xstream adapter &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4703&quot;&gt;DBZ-4703&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Migrating UI from webpack-dev-server v3 to v4 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4642&quot;&gt;DBZ-4642&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade postgres driver to version 42.3.2 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4658&quot;&gt;DBZ-4658&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Quarkus 2.7.0.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4677&quot;&gt;DBZ-4677&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Update shared UG deployment file for use with downstream OCP Install Guide &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4700&quot;&gt;DBZ-4700&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Indicate ROWID is not supported by XStream &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4702&quot;&gt;DBZ-4702&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental snapshots does not honor column case sensitivity &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4584&quot;&gt;DBZ-4584&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Build trigger issues &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4672&quot;&gt;DBZ-4672&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cannot expand JSON payload with nested arrays of objects &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4704&quot;&gt;DBZ-4704&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will also be backporting the critical bugfixes to the 1.8 branch and will release Debezium 1.8.1.Final later this week.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/isacandrei&quot;&gt;Andrei Isac&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/daha&quot;&gt;David Haglund&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuyar&quot;&gt;Farid Uyar&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jmks&quot;&gt;Jason Schweier&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.9 series, 1.9.0.Alpha2! This release includes support for Oracle 21c, improvements around Redis for Debezium Server, configuring the kafka.query.timeout.ms option, and a number of bug fixes around DDL parsers, build infrastructure, etc. Overall, the community fixed 51 issues for this release. Let’s take a closer look at some of the highlights.</summary></entry><entry><title type="html">Debezium 1.9.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Alpha1 Released"/><published>2022-01-26T00:00:00+00:00</published><updated>2022-01-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.9 series, &lt;strong&gt;1.9.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the new year comes a new release! The Debezium 1.9.0.Alpha1 release comes with quite a number of fixes and improvements, most notably improved metrics and Oracle ROWID data type support.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improved_metrics&quot;&gt;Improved Metrics&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium&amp;#8217;s connectors provide a wide range of metrics. We have expanded upon the &lt;code&gt;TotalNumberOfEventsSeen&lt;/code&gt; metric to provide a breakdown of those events by type. To support this endeavor, the following new metrics have been added:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfCreateEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfUpdateEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfDeleteEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These metrics represent the number of &lt;em&gt;insert&lt;/em&gt;, &lt;em&gt;update&lt;/em&gt;, and &lt;em&gt;delete&lt;/em&gt; events respectively that have occurred since the start of the connector&amp;#8217;s streaming phase. So not only can you continue to get the total number of events aggregate, but you can now get a breakdown of that total by event type.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_rowid_data_type_support&quot;&gt;Oracle ROWID data type support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle users may elect to use a &lt;code&gt;ROWID&lt;/code&gt; data type column as an optimization to represent a relationship between the current row and the row identified by the &lt;code&gt;ROWID&lt;/code&gt; column value. Starting with this release, columns using the &lt;code&gt;ROWID&lt;/code&gt; data type can be captured by Debezium and emitted in change events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle has two flavors of row identifier column data types, &lt;code&gt;ROWID&lt;/code&gt; and &lt;code&gt;UROWID&lt;/code&gt;. While these may be used interchangeably in some contexts, they&amp;#8217;re very different in the context of change data capture events. Although we&amp;#8217;ve added support for &lt;code&gt;ROWID&lt;/code&gt;, support for &lt;code&gt;UROWID&lt;/code&gt; remains unsupported at this time.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;JSON Payload not expanding when enabling it (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4457&quot;&gt;DBZ-4457&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;R/O incremental snapshot can blocks the binlog stream on restart (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4502&quot;&gt;DBZ-4502&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan doesn&amp;#8217;t work with underscores inside cache names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4526&quot;&gt;DBZ-4526&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Can&amp;#8217;t process column definition with length exceeding Integer.MAX_VALUE (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4583&quot;&gt;DBZ-4583&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector can&amp;#8217;t find the SCN (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4597&quot;&gt;DBZ-4597&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Update Postgres JDBC driver to 42.3.1 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4374&quot;&gt;DBZ-4374&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade SQL Server driver to 9.4 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4463&quot;&gt;DBZ-4463&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;100 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/hjwalt&quot;&gt;Hady Willi&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/wndemon&quot;&gt;Nansen&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/0sc&quot;&gt;Oscar Romero&lt;/a&gt;, &lt;a href=&quot;https://github.com/poonam-meghnani&quot;&gt;Poonam Meghnani&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhongqishang&quot;&gt;Qishang Zhong&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarumont&quot;&gt;Richard Kolkovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sebruck&quot;&gt;Sebastian Bruckner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, and &lt;a href=&quot;https://github.com/AChangFeng&quot;&gt;胡琴&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have started an &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. Your feedback is invaluable so let us know what you&amp;#8217;d like to see added, changed, or improved!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the meantime, we&amp;#8217;re just getting started! There will be another 1.9 pre-release in the coming weeks, sticking with our 3-week cadence. You can also expect a bugfix release sometime this quarter for 1.8 as we continue to get community feedback.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.9 series, 1.9.0.Alpha1! With the new year comes a new release! The Debezium 1.9.0.Alpha1 release comes with quite a number of fixes and improvements, most notably improved metrics and Oracle ROWID data type support.</summary></entry><entry><title type="html">Debezium 1.8.0.Final Released</title><link href="https://debezium.io/blog/2021/12/16/debezium-1.8-final-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Final Released"/><published>2021-12-16T00:00:00+00:00</published><updated>2021-12-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/16/debezium-1.8-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/12/16/debezium-1.8-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my great pleasure to announce the release of Debezium &lt;strong&gt;1.8.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides a strong focus on the Debezium connector for MongoDB (more on that below), the 1.8 release brings support for Postgres' logical decoding messages, support for configuring SMTs and topic creation settings in the Debezium UI, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4460?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.8.0.Alpha1%2C%201.8.0.Alpha2%2C%201.8.0.Beta1%2C%201.8.0.CR1%2C%201.8.0.Final)&quot;&gt;242 issues&lt;/a&gt; for this release. A big thank you to everyone who helped to make this release happen on time, sticking to our quarterly release cadence!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improvements_to_the_debezium_connector_for_mongodb&quot;&gt;Improvements to the Debezium Connector for MongoDB&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The team has made a strong push to bring multiple new features and improvements to the &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html&quot;&gt;connector for MongoDB&lt;/a&gt;. It has now a brand-new capturing implementation based on MongoDB &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/&quot;&gt;Change Streams&lt;/a&gt;, which allows for some very exciting new functionalities. More specifically, the connector now&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Supports and has been tested with all the latest versions up to 5.0&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Can optionally &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html#mongodb-property-capture-mode&quot;&gt;emit the complete document state&lt;/a&gt; for update events (by means of the Change Streams capability of reading back the entire document affected by change)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provides support for &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html#_incremental_snapshot&quot;&gt;incremental snapshots&lt;/a&gt;, as already known from the other Debezium connectors (more details on that in a separate blog post)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Helps you to implement the outbox pattern for microservices data exchange by means of an &lt;a href=&quot;https://debezium.io/documentation/reference/stable/transformations/mongodb-outbox-event-router.html&quot;&gt;event routing SMT&lt;/a&gt;, specifically tailored to the event format emitted by this connector&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements&quot;&gt;Further Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides the work on the MongoDB connector, many improvements and feature additions have been made to the other connectors. Amongst other things,&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The names of transaction metadata topics are configurable&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium UI has been further built out (see &lt;a href=&quot;/blog/2021/11/23/debezium-ui-transforms/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/blog/2021/12/02/debezium-ui-topic-groups/&quot;&gt;here&lt;/a&gt; for demos of this)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Postgres now &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-message-events&quot;&gt;supports logical decoding messages&lt;/a&gt;, as emitted using the &lt;code&gt;pg_logical_emit_message()&lt;/code&gt; function&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;There&amp;#8217;s a new snapshot mode &lt;code&gt;SCHEMA_ONLY_RECOVERY&lt;/code&gt; for the Debezium connector for Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Oracle supports &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-truncate-events&quot;&gt;&lt;code&gt;TRUNCATE&lt;/code&gt; events&lt;/a&gt; and the &lt;code&gt;binary.handling.mode&lt;/code&gt; option for controlling how BLOB data is exported&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;There&amp;#8217;s support for &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-event-buffering-infinispan&quot;&gt;remote Infinispan caches&lt;/a&gt; for buffering large Oracle transactions&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for MySQL now can export table comments; it also supports heartbeat action queries and schema changes while an incremental snapshot is running; in addition, it received many improvements to its DDL parser and character set handling&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Vitess supports transaction metadata events, has an improved &lt;code&gt;source&lt;/code&gt; struct, and supports re-sharding operations in a more flexible way&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please take a look at the original release announcements (&lt;a href=&quot;/blog/2021/10/27/debezium-1-8-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/11/11/debezium-1.8-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2021/11/30/debezium-1.8-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, and &lt;a href=&quot;/blog/2021/12/09/debezium-1.8-cr1-released/&quot;&gt;CR1&lt;/a&gt;) as well as the &lt;a href=&quot;/releases/1.8/release-notes&quot;&gt;1.8 release notes&lt;/a&gt; in order to learn more about these and other new features of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to all the folks from the Debezium community which contributed code changes to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/abhishekkh&quot;&gt;Abhishek Hodavdekar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Ashique Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/bgaraue&quot;&gt;Biel Garau Estarellas&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/cburch824&quot;&gt;Christopher Burch&lt;/a&gt;, &lt;a href=&quot;https://github.com/kometen&quot;&gt;Claus Guttesen&lt;/a&gt;, &lt;a href=&quot;https://github.com/danielpetisme&quot;&gt;Daniel PETISME&lt;/a&gt;, &lt;a href=&quot;https://github.com/famartinrh&quot;&gt;Fabian Martinez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/gkorland&quot;&gt;Guy Korland&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/lairen&quot;&gt;Lairen Hightower&lt;/a&gt;, &lt;a href=&quot;https://github.com/lbroudoux&quot;&gt;Laurent Broudoux&lt;/a&gt;, &lt;a href=&quot;https://github.com/lujiefsi&quot;&gt;陆杰&lt;/a&gt;, &lt;a href=&quot;https://github.com/xenji&quot;&gt;Mario Mueller&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, &lt;a href=&quot;https://github.com/unalsurmeli&quot;&gt;Ünal Sürmeli&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ashulin&quot;&gt;Zongwen Li&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With another release shipped on schedule, it&amp;#8217;s time for a break and take a rest over the upcoming holidays. We&amp;#8217;ll be back to business in early January, with the planning for the 1.9 release being the first activity.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please let us know about any requirements and feature requests you may have. One area we&amp;#8217;d like to focus on for the next release is performance benchmarking and subsequentially applying performance improvements based on that. It also looks like there will be new community-led Debezium connector for a distributed NoSQL store; stay tuned for the details around this super-exciting development!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Later in the year, you also can expect the release of Debezium 2.0, where we&amp;#8217;ll focus on cleaning up some inconsistencies and removing some deprecated features such as wal2json support in the Debezium connector for Postgres.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For now, we wish everybody a happy holiday season, and, if you&amp;#8217;re into it, Merry Christmas! Please note the core team will be on PTO mostly for the coming weeks, so replies to emails, chat messages, issue reports, and pull requests will be slower than usual. Upwards and onwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my great pleasure to announce the release of Debezium 1.8.0.Final! Besides a strong focus on the Debezium connector for MongoDB (more on that below), the 1.8 release brings support for Postgres' logical decoding messages, support for configuring SMTs and topic creation settings in the Debezium UI, and much more. Overall, the community has fixed 242 issues for this release. A big thank you to everyone who helped to make this release happen on time, sticking to our quarterly release cadence!</summary></entry><entry><title type="html">Note on log4j Security</title><link href="https://debezium.io/blog/2021/12/14/note-on-log4j-security/" rel="alternate" type="text/html" title="Note on log4j Security"/><published>2021-12-14T00:00:00+00:00</published><updated>2021-12-14T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/14/note-on-log4j-security</id><content type="html" xml:base="https://debezium.io/blog/2021/12/14/note-on-log4j-security/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;TL,DR: Debezium is NOT affected by the recently disclosed remote code execution vulnerability in log4j2 (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2021-44228&quot;&gt;CVE-2021-44228&lt;/a&gt;); The log4j-1.2.17.jar shipped in Debezium&amp;#8217;s container images contains a class &lt;code&gt;JMSAppender&lt;/code&gt;, which is subject to a MODERATE vulnerability (&lt;a href=&quot;https://access.redhat.com/security/cve/CVE-2021-4104&quot;&gt;CVE-2021-4104&lt;/a&gt;). This appender is NOT used by default, i.e. access to log4j&amp;#8217;s configuration is required in order to exploit this CVE. As a measure of caution, we have decided to remove the &lt;code&gt;JMSAppender&lt;/code&gt; class from Debezium&amp;#8217;s container images as of version 1.7.2.Final, released today.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On Dec 10th, a remote code execution vulnerability in the widely used log4j2 library was published (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2021-44228&quot;&gt;CVE-2021-44228&lt;/a&gt;). Debezium, just like Apache Kafka and Kafka Connect, does not use log4j2 and therefore is NOT affected by this CVE.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apache Kafka, Kafka Connect and Apache ZooKeeper do use log4j 1.x though, which therefore is shipped as part of &lt;a href=&quot;https://quay.io/organization/debezium&quot;&gt;Debezium&amp;#8217;s container images&lt;/a&gt; for these components. On Dec 13th, a MODERATE vulnerability in log4j 1.x was published (&lt;a href=&quot;https://access.redhat.com/security/cve/CVE-2021-4104&quot;&gt;CVE-2021-4104&lt;/a&gt;), affecting the &lt;code&gt;JMSAppender&lt;/code&gt; class coming with log4j 1.x. This vulnerability &quot;allows a remote attacker to execute code on the server if the deployed application is configured to use &lt;code&gt;JMSAppender&lt;/code&gt; and to the attacker&amp;#8217;s JMS Broker&quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This appender is NOT used by default, i.e. &quot;this flaw ONLY affects applications which are specifically configured to use &lt;code&gt;JMSAppender&lt;/code&gt;, which is not the default, or when the attacker has write access to the Log4j configuration for adding &lt;code&gt;JMSAppender&lt;/code&gt; to the attacker&amp;#8217;s JMS Broker&quot;. If you are using &lt;code&gt;JMSAppender&lt;/code&gt;, you should verify and ensure that you are using trustworthy configuration values for its &lt;code&gt;TopicBindingName&lt;/code&gt; and &lt;code&gt;TopicConnectionFactoryBindingName&lt;/code&gt; settings.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using a JMS-based appender should only very rarely occur in the context of Apache Kafka, if at all. As a measure of caution, we have therefore decided to remove the &lt;code&gt;JMSAppender&lt;/code&gt; class from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; JAR contained in Debezium&amp;#8217;s container images for Apache Kafka, Kafka Connect, and Apache ZooKeeper. At the same time, we are also removing the &lt;code&gt;SocketServer&lt;/code&gt; class from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt;, which is subject to another, unrelated CVE (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2019-17571&quot;&gt;CVE-2019-17571&lt;/a&gt;). This is a separate main class, not used in any way by Debezium, Kafka, Kafka Connect, or ZooKeeper, but we decided to not ship it any longer, thus making the Debezium container images not subject to this CVE either.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note that if you are running the Debezium connectors via other distributions of Apache Kafka and related components, the &lt;code&gt;JMSAppender&lt;/code&gt; and &lt;code&gt;SocketServer&lt;/code&gt; classes may be present in their &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt;, and you thus should make sure to either not use them at all, or only use them in safe way. Access to log4j&amp;#8217;s configuration should be secured in an appropriate way.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other distributables of Debezium, such as the individual connector archives, or the Debezium Server distribution, do not contain &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; and thus are NOT subject to the mentioned CVEs in any way.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The removal of the &lt;code&gt;JMSAppender&lt;/code&gt; and &lt;code&gt;SocketServer&lt;/code&gt; classes from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; shipped with Debezium&amp;#8217;s container images is effective as of Debezium 1.7.2.Final, which was released earlier today. We recommend to update to this version to all users.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you have any questions around this topic, please join the discussion on &lt;a href=&quot;https://groups.google.com/g/debezium/c/W3jYvNc-d5M&quot;&gt;this thread&lt;/a&gt; on the Debezium mailling list. If you have any other security-related concerns around Debezium, please do NOT publicly discuss them, but file a Jira issue with limited visibility in our &lt;a href=&quot;https://issues.redhat.com/browse/DBZ&quot;&gt;bug tracker&lt;/a&gt;, and we will follow up with you on this as quickly as possible.&lt;/p&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><summary type="html">TL,DR: Debezium is NOT affected by the recently disclosed remote code execution vulnerability in log4j2 (CVE-2021-44228); The log4j-1.2.17.jar shipped in Debezium&amp;#8217;s container images contains a class JMSAppender, which is subject to a MODERATE vulnerability (CVE-2021-4104). This appender is NOT used by default, i.e. access to log4j&amp;#8217;s configuration is required in order to exploit this CVE. As a measure of caution, we have decided to remove the JMSAppender class from Debezium&amp;#8217;s container images as of version 1.7.2.Final, released today. On Dec 10th, a remote code execution vulnerability in the widely used log4j2 library was published (CVE-2021-44228). Debezium, just like Apache Kafka and Kafka Connect, does not use log4j2 and therefore is NOT affected by this CVE.</summary></entry><entry><title type="html">Debezium 1.8.0.CR1 Released</title><link href="https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.CR1 Released"/><published>2021-12-09T00:00:00+00:00</published><updated>2021-12-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very excited to announce the release of Debezium &lt;strong&gt;1.8.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As were near the final release due out next week, this release focused heavily on bugfixes. Yet this release includes incremental snapshot support for MongoDB! Overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.CR%20ORDER%20BY%20component%20ASC&quot;&gt;34 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at some of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_incremental_snapshots&quot;&gt;MongoDB incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting is a feature that we first introduced as a part of Debezium 1.6 nearly six months ago. The goals of incremental snapshots is to primarily address to very common user pain-points:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;the necessity to execute consistent snapshots before streaming can begin upon connector restart&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;inability to trigger full or partial snapshots after connector has begun streaming&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The implementation of this feature is based on a novel approach to snapshotting originally invented by the &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;DBLog Framework&lt;/a&gt; from Netflix. Debezium&amp;#8217;s implementation is described in the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;design document&lt;/a&gt;, and we also published an in-depth &lt;a href=&quot;https://debezium.io/blog/2021/10/07/incremental-snapshots/&quot;&gt;blog post&lt;/a&gt; discussing our implementation in greater detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With this release, we&amp;#8217;re excited to finally debut this feature for MongoDB. All Debezium core connectors now support this feature; an amazing milestone!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;d like to thank our very own &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt; and &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Kate Galieva&lt;/a&gt; from Shopify for their amazing efforts these last few months at refining and delivering on this feature as well as the entire community for testing and offering solid feedback.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With 1.8 Final release scheduled for next week, a vast majority of the changes in this release focus on stability and bugfixes. Some resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[Oracle] None of log files contains offset SCN (SCN offset is no longer available in the online redo logs) (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3635&quot;&gt;DBZ-3635&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] Add support for truncate in Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4385&quot;&gt;DBZ-4385&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] Support &lt;code&gt;binary_handling_mode&lt;/code&gt; for Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4400&quot;&gt;DBZ-4400&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Debezium Server] Event Hubs exporter slow/Event data was too large (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4277&quot;&gt;DBZ-4277&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] Enforce consistent vgtid representation in Vitess connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4409&quot;&gt;DBZ-4409&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] VStream gRPC connection closed after being idle for a few minutes (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4389&quot;&gt;DBZ-4389&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4397&quot;&gt;DBZ-4397&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4402&quot;&gt;DBZ-4402&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4388&quot;&gt;DBZ-4388&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4396&quot;&gt;DBZ-4396&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.8/release-notes#release-1.8.0-cr1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, and &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the year is coming to close, we&amp;#8217;re actively preparing some holiday treats!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can expect 1.7.2.Final to be released early next week including many bugfixes and improvements. Additionally, we intend to release 1.8.0.Final in the middle of next week barring no unforeseen bug reports with CR1.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After the holiday break, we plan to be back in full swing on Debezium 1.9. Keep at eye on our &lt;a href=&quot;https://debezium.io/roadmap&quot;&gt;road map&lt;/a&gt; as we&amp;#8217;ll be updating this to include our focus for next quarter&amp;#8217;s release cycle.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re also actively working on the planning and scope of Debezium 2.0 which we intend to release sometime in 2022. We would love your feedback on any features or changes you&amp;#8217;d like to see so join the discussion on this topic on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m very excited to announce the release of Debezium 1.8.0.CR1! As were near the final release due out next week, this release focused heavily on bugfixes. Yet this release includes incremental snapshot support for MongoDB! Overall, not less than 34 issues have been fixed for this release. Let&amp;#8217;s take a closer look at some of them.</summary></entry><entry><title type="html">Configuring Automatic Topic Creation With the Debezium UI</title><link href="https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups/" rel="alternate" type="text/html" title="Configuring Automatic Topic Creation With the Debezium UI"/><published>2021-12-02T00:00:00+00:00</published><updated>2021-12-02T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups</id><content type="html" xml:base="https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team continues to add support for more features, allowing users to more easily configure connectors. In this article, we&amp;#8217;ll describe and demonstrate the UI support for topic automatic creation. Read further for more information, including a video demo!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;topic_auto_creation&quot;&gt;Topic Auto-creation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When you start a Debezium connector, the topics for the captured events are created by the Kafka broker based on a default, possibly customized, broker configuration (if &lt;code&gt;auto.create.topics.enable = true&lt;/code&gt;). But often when you use Debezium and Kafka in a production environment, you might choose to disable Kafka’s topic auto creation capability (&lt;code&gt;auto.create.topics.enable = false&lt;/code&gt;), or you want the connector topics to be configured differently from the default. In this case you&amp;#8217;ll need to create topics for Debezium’s captured data sources upfront.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Beginning with Kafka 2.6.0, Kafka Connect provides means of customizing the settings of specififc topics created by source connectors such as Debezium (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics&quot;&gt;KIP-158&lt;/a&gt;). If Kafka Connect topic creation is enabled (&lt;code&gt;topic.creation.enable = true&lt;/code&gt;), the Debezium UI now allows you to configure connector topics using the UI.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_connect_topic_creation&quot;&gt;Kafka Connect Topic Creation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Kafka Connect topic creation works with groups. There is a &lt;code&gt;default&lt;/code&gt; group, which is used when there is no other group defined that matches the topic.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can also define multiple custom topic groups, each with it&amp;#8217;s own configuration. Each group can specify its configuration parameters to customize how the matched topics of the group will be created. The custom groups will fall back to the default group settings for the required &lt;code&gt;replication.factor&lt;/code&gt; and &lt;code&gt;partitions&lt;/code&gt; properties. If the configuration for a custom topic group leaves other properties undefined, the values specified in the default group are not applied.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To find more detail about topic auto-creation with Debezium, please refer to the &lt;a href=&quot;/documentation/reference/configuration/topic-auto-create-config.html&quot;&gt;reference documentation&lt;/a&gt;. You can also refer to this &lt;a href=&quot;/blog/2020/09/15/debezium-auto-create-topics/&quot;&gt;blog post&lt;/a&gt; for a full example. Watch the following video for a quick demo of topic creation in the Debezium UI:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/C7K1V833eDk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;self_contained_example&quot;&gt;Self-contained Example&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can try out topic auto-creation (and more) with our self-contained example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;UI demo&lt;/a&gt; - which is included under &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;debezium-examples&lt;/a&gt; on GitHub. The UI demo includes a Docker Compose file which brings up several sources with data as well as the UI. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;README file&lt;/a&gt; for more details on running the Debezium UI demo.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the Debezium UI, please refer to the &lt;a href=&quot;/documentation/reference/operations/debezium-ui.html&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;more_coming_soon&quot;&gt;More coming soon!&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Stay tuned for further improvements and new features in the UI in the coming releases. Support for SQL Server and Oracle connectors are coming soon!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team who have contributed in many ways: Ashique Ansari, Indra Shukla, René Kerner and Gunnar Morling!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Mark Drilling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongo"/><category term="debezium-ui"/><summary type="html">The Debezium UI team continues to add support for more features, allowing users to more easily configure connectors. In this article, we&amp;#8217;ll describe and demonstrate the UI support for topic automatic creation. Read further for more information, including a video demo!</summary></entry><entry><title type="html">Debezium 1.8.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Beta1 Released"/><published>2021-11-30T00:00:00+00:00</published><updated>2021-11-30T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.8.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is packed with exciting new features like support for MongoDB 5.0, an outbox event router for the MongoDB connector and support for Postgres logical decoding messages, as well as tons of bugfixes and other improvements. Overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;63 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at some of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_outbox_event_router&quot;&gt;MongoDB Outbox Event Router&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The outbox pattern is becoming more and more popular for &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;exchanging data between microservices in a reliable way&lt;/a&gt;, without using unsafe &lt;em&gt;dual writes&lt;/em&gt; to a service&amp;#8217;s database and Apache Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the outbox pattern, instead of capturing changes from your actual business tables, you write messages to be sent to external consumers into a dedicated outbox table. This nicely decouples your internal data model from the message contracts used for communicating with external services, allowing you to develop and evolve these independently. Updates to your business tables and inserts into the outbox table are done within one database transaction, so that either both of these things are done, or none of them. Once a message has been persisted in the outbox table, Debezium can capture it from there and propagate it to any consumers using the usual at-least-once semantics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium provides support for implementing the outbox pattern via a special single message transform (SMT), the &lt;a href=&quot;/documentation/reference/stable/transformations/outbox-event-router.html&quot;&gt;outbox event router&lt;/a&gt;. This takes care of routing events from the single outbox table to different topics, based on a configurable column representing the aggregate type (in the parlance of domain driven design) the event is for. In addition, there is an &lt;a href=&quot;/documentation/reference/1.8/integrations/outbox.html&quot;&gt;extension for emitting outbox events&lt;/a&gt; from services built using &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;, a stack for building cloud-native microservices.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These things are complemented now by a new &lt;a href=&quot;/documentation/reference/1.8/transformations/mongodb-outbox-event-router.html&quot;&gt;event routing SMT&lt;/a&gt; which works with the Debezium connector for MongoDB. As the MongoDB connector&amp;#8217;s event format differs from the format of the Debezium connectors for relational databases, creating this separate SMT became necessary. Here&amp;#8217;s an example for configuring the SMT:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;outbox-connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector.class&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.mongodb.MongoDbConnector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tasks.max&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.hosts&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0/mongodb:27017&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.user&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;debezium&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.password&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbz&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory.outboxevent&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.history.kafka.bootstrap.servers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;kafka:9092&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;outbox&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.route.topic.replacement&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;${routedByValue}.events&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.expand.json.payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.field.event.timestamp&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.fields.additional.placement&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type:header:eventType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.storage.StringConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.storage.StringConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here we&amp;#8217;re using the &lt;code&gt;MongoEventRouter&lt;/code&gt; SMT for capturing changes from the &lt;code&gt;inventory.outboxevent&lt;/code&gt; collection. Events could be written like so, using the MongoDB CLI as an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;new_order = { &quot;_id&quot; : ObjectId(&quot;000000000000000000000002&quot;), &quot;order_date&quot; : ISODate(&quot;2021-11-22T00:00:00Z&quot;), &quot;purchaser_id&quot; : NumberLong(1004), &quot;quantity&quot; : 1, &quot;product_id&quot; : NumberLong(107) } s = db.getMongo().startSession() s.startTransaction() s.getDatabase(&quot;inventory&quot;).orders.insert(new_order) s.getDatabase(&quot;inventory&quot;).outboxevent.insert({ _id : ObjectId(&quot;000000000000000000000001&quot;), aggregateid : new_order._id, aggregatetype : &quot;Order&quot;, type : &quot;OrderCreated&quot;, timestamp: NumberLong(1556890294484), payload : new_order }) s.commitTransaction()&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note how we&amp;#8217;re doing the inserts into a business collection (&quot;orders&quot;) and into the outbox collection (&quot;outboxevent&quot;) within a transaction, as supported by MongoDB since version 4.0. While we are using the actual order object in the outbox message itself in this particular case, we also could separate these things and choose another representation of the purchase orders in the outbox events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The id of the order &lt;em&gt;aggregate&lt;/em&gt; is used as the message key in Kafka, ensuring consistent ordering of all outbox events pertaining to a given purchase order. The &lt;em&gt;aggregate type&lt;/em&gt; is used for determining the name of the topic to route events to, &lt;code&gt;Order.events&lt;/code&gt; in this example. The unique &lt;em&gt;id of the message&lt;/em&gt; itself is propagated as a header in the Kafka message, for instance allowing consumers to identify duplicated messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can find a &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/mongodb-outbox&quot;&gt;complete example&lt;/a&gt; for using this new MongoDB outbox event routing SMT in our &lt;a href=&quot;https://github.com/debezium/debezium-examples/&quot;&gt;demos repository&lt;/a&gt;. A massive thank you to &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, who not only provided the actual feature implementation itself, but also created this example.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Potential next steps around outbox support for the Debezium MongoDB connector may be adding support for MongoDB to the Quarkus outbox extension, and having an option to capture outbox events from sub-documents attached to an entity like &lt;code&gt;Order&lt;/code&gt;. That way, your application&amp;#8217;s data and the outbox message could be written as a single document (the application would otherwise ignore the outbox sub-document itself) and not requiring cross-document transactions. This idea is tracked via &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4319&quot;&gt;DBZ-4319&lt;/a&gt;; please let us know if you think that&amp;#8217;d be a useful addition or if you&amp;#8217;d even be interested in implementing it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_postgres_pg_logical_emit_message&quot;&gt;Support for Postgres' &lt;code&gt;pg_logical_emit_message()&lt;/code&gt;&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The versatility and flexibility of Postgres is legend; one of the interesting and lesser known features is the ability to write messages into the database&amp;#8217;s transaction log (WAL), without writing to a table actually. This is done via the &lt;a href=&quot;https://www.postgresql.org/docs/14/functions-admin.html#FUNCTIONS-REPLICATION&quot;&gt;&lt;code&gt;pg_logical_emit_message()&lt;/code&gt;&lt;/a&gt; function. &lt;a href=&quot;http://amitkapila16.blogspot.com/2021/09/logical-replication-improvements-in.html&quot;&gt;As of Postgres 14&lt;/a&gt;, these logical decoding messages can be captured using the &lt;code&gt;pgoutput&lt;/code&gt; plug-in, and Debezium also supports this event type as of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Logical decoding messages are great for propagating contextual information associated to your transactions, without having to store this data in a table. This could for instance be &lt;a href=&quot;/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/&quot;&gt;auditing metadata&lt;/a&gt; such as a business user who triggered some data change. Another potential use case is the outbox pattern mentioned above, which could be implemented without a dedicated outbox table, solely by writing outbox events to the WAL. That&amp;#8217;s advantageous for instance when thinking about house-keeping: there&amp;#8217;d be no need for removing messages from an outbox table after they have been propagated to Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&quot;Sending&quot; a logical decoding message is as simple as that:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; pg_logical_emit_message(&lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some-prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some text&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This emits a message which is transactional (&lt;code&gt;true&lt;/code&gt;), with the &quot;some-prefix&quot; prefix and &quot;some text&quot; as the message contents. The prefix can be used for grouping messages into logical contexts. Debezium uses the prefix as the Kafka message key, i.e. all messages with the same prefix will go into the same partition of the corresponding Kafka topic and thus will be propagated in the same order to downstream consumers as they were created.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Logical decoding messages are emitted by the Debezium Postgres connector using a new event type (&quot;m&quot;) and look like so (the message content is binary-encoded, using Base64 in this example):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Beta1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgresql&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;PostgreSQL_server&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1559033904863&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;556&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lsn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;46523128&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;xmin&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1559033904961&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some-prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;c29tZSB0ZXh0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The message contents is an arbitrary payload, besides the textual represention you also can insert binary data here. It is the responsibility of the event producer to document the format, evolve it with backwards compatibility in mind, and exchange schema information with any clients. One great way of doing so would be to take advantage of a schema registry such as &lt;a href=&quot;https://www.apicur.io/registry/&quot;&gt;Apicurio&lt;/a&gt;. You also could think of using a standard like &lt;a href=&quot;https://cloudevents.io/&quot;&gt;CloudEvents&lt;/a&gt; for your logical decoding messages, which then for instance would allow an SMT such as the aforementioned outbox event router to take action based on defined attributes in the event structure.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about support for logical decoding messages in Debezium, please refer to the &lt;a href=&quot;/documentation/reference/1.8/connectors/postgresql.html#postgresql-message-events&quot;&gt;connector documentation&lt;/a&gt;. Thanks a lot to Lairen Hightower for implementing this feature!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_and_changes&quot;&gt;Other Fixes and Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in the 1.8.0.Beta1 release include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for configuring SMTs and topic creation settings in the Debezium UI; you can see the former in a quick video in &lt;a href=&quot;/blog/2021/11/23/debezium-ui-transforms/&quot;&gt;this post&lt;/a&gt;, and we&amp;#8217;ll share another demo of the topic creation UI later this week&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Transaction metadata events in the Vitess connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4355&quot;&gt;DBZ-4355&lt;/a&gt;); we also simplified its configuration by removing the dependency to vtctld (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4324&quot;&gt;DBZ-4324&lt;/a&gt;), added support for the &lt;code&gt;stop_on_reshard&lt;/code&gt; flag (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4295&quot;&gt;DBZ-4295&lt;/a&gt;), and provided the ability to specify a VGTID as the starting point for streaming (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4297&quot;&gt;DBZ-4297&lt;/a&gt;). All these changes were contributed by Yang Wu and Shichao from the Stripe engineering team, who agreed to step up as maintainers of this connector. Thanks a lot, and welcome!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;More flexible configuration of the Infinispan-based transaction buffer of the Debezium connector for Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4169&quot;&gt;DBZ-4169&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improved type mappings for &lt;code&gt;MONEY&lt;/code&gt; columns in Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1931&quot;&gt;DBZ-1931&lt;/a&gt;) and &lt;code&gt;INTERVAL&lt;/code&gt; columns in Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1539&quot;&gt;DBZ-1539&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for schema changes while doing an incremental snapshot with the Debezium connector for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4196&quot;&gt;DBZ-4196&lt;/a&gt;); thanks to Kate Galieva for this very useful improvement!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.8/release-notes#release-1.8.0-beta1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Ashique Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/bgaraue&quot;&gt;Biel Garau Estarellas&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/danielpetisme&quot;&gt;Daniel Petisme&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/lairen&quot;&gt;Lairen Hightower&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the Beta1 release out, we&amp;#8217;re approaching the final phase of the 1.8 release cycle. You can expect a CR1 sometime next week, and depending on incoming issue reports, we may decide to cut the Final release either in the week before Christmas, or in the first week of 2022. In terms of features to be added, one thing we&amp;#8217;d love to get to is incremental snapshotting support for the MongoDB connector. We&amp;#8217;ll have to see whether this will make it in the remaining time, or whether this will have to wait for the Debezium 1.9 release. While the 1.8 release line is maturing, you also can look forward to the release of Debezium 1.7.2.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, we&amp;#8217;re also continuing our planning around Debezium 2.0, which should be released sometime next year. Please join the discussion on this topic on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.8.0.Beta1! This release is packed with exciting new features like support for MongoDB 5.0, an outbox event router for the MongoDB connector and support for Postgres logical decoding messages, as well as tons of bugfixes and other improvements. Overall, not less than 63 issues have been fixed for this release. Let&amp;#8217;s take a closer look at some of them.</summary></entry><entry><title type="html">Debezium UI support for Single Message Transformations</title><link href="https://debezium.io/blog/2021/11/23/debezium-ui-transforms/" rel="alternate" type="text/html" title="Debezium UI support for Single Message Transformations"/><published>2021-11-23T00:00:00+00:00</published><updated>2021-11-23T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/23/debezium-ui-transforms</id><content type="html" xml:base="https://debezium.io/blog/2021/11/23/debezium-ui-transforms/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team is pleased to announce support for Single Message Transformations (SMTs) in the Debezium UI!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our goal with the Debezium graphical user interface is to allow users to set up and operate connectors more easily. To that end, we have added support for Kafka Connect &lt;a href=&quot;https://kafka.apache.org/documentation/#connect_transforms&quot;&gt;single message transformations&lt;/a&gt; to the UI. Read futher for more information, and for a video demo of the new feature!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;single_message_transformations_smts&quot;&gt;Single Message Transformations (SMTs)&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Connectors can be configured with transformations to make lightweight per message modifications. &lt;a href=&quot;https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/&quot;&gt;Common SMT use cases&lt;/a&gt; include format conversions (e.g. different date formats and number types), message filtering and routing, handling of &quot;tombstone&quot; events, encryption/decryption, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium provides several single message transformations (SMTs) that you can use to either modify records before they are sent to Apache Kafka (by applying them to the Debezium connectors), or when they are read from Kafka by a sink connector. For instance we provide SMTs for extracting only the &quot;after&quot; part from change events and propagate that one in a flat row format and SMTs for routing the events from an outbox table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the SMTs coming with Debezium, please refer to the &lt;a href=&quot;/documentation/reference/transformations/index.html&quot;&gt;reference documentation&lt;/a&gt;. And thanks to the support for SMTs in the Debezium UI, setting them up is easier than ever; For a short demo of this feature in action, see the following video:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/F5o0Zyjlpeg&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Fun fact: this video is the very first entry to our brand-new &lt;a href=&quot;https://www.youtube.com/channel/UCk8VviAaxNZkakaL1hPykIg&quot;&gt;Debezium YouTube channel&lt;/a&gt;! We recommend you subscribe to the channel to never miss any new videos.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;trying_it_out_yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have created a self-contained example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;UI demo&lt;/a&gt;, which is included under &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;debezium-examples&lt;/a&gt; on Github. The UI demo includes a Docker Compose file which brings up several sources with data as well as the UI. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;README file&lt;/a&gt; for more details on running the Debezium UI demo.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the Debezium UI, please refer to the &lt;a href=&quot;/documentation/reference/stable/operations/debezium-ui.html&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;next_steps&quot;&gt;Next Steps&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We plan to continue with improvements and new features for the UI in the coming releases. Some items under consideration:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Incorporation of more Debezium connector types, such as the ones for SQL Server and Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Addition and improvement of connector metrics and monitoring&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add capability for viewing and editing connector properties after creation&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&amp;#8230;&amp;#8203;And more!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;d also be very happy to learn about your requirements and feedback on the Debezium UI. Please let us know in the comments below, or send a message to our &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team who have contributed in many ways: Ashique Ansari, Indra Shukla, René Kerner and Gunnar Morling!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Mark Drilling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongo"/><category term="debezium-ui"/><summary type="html">The Debezium UI team is pleased to announce support for Single Message Transformations (SMTs) in the Debezium UI! Our goal with the Debezium graphical user interface is to allow users to set up and operate connectors more easily. To that end, we have added support for Kafka Connect single message transformations to the UI. Read futher for more information, and for a video demo of the new feature!</summary></entry><entry><title type="html">Debezium 1.8.0.Alpha2 Released</title><link href="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha2 Released"/><published>2021-11-11T00:00:00+00:00</published><updated>2021-11-11T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;MySQL support for heartbeat action queries&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Configurable transaction topic name&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, the latest &lt;code&gt;1.2&lt;/code&gt; tag of the &lt;a href=&quot;https://hub.docker.com/repository/docker/debezium/tooling&quot;&gt;debezium/tooling&lt;/a&gt; image is available. The newest version includes all the latest tools, including &lt;a href=&quot;https://github.com/kcctl/kcctl&quot;&gt;kcctl&lt;/a&gt;, a super simple, cuddly CLI for Apache Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release does include several breaking changes. Please see the &lt;a href=&quot;https://debezium.io/releases/1.8/release-notes#release-1.8.0-alpha2&quot;&gt;release notes&lt;/a&gt; for details on what changed and how to upgrade.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mysql_heartbeat_action_query_support&quot;&gt;MySQL heartbeat action query support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat action query can be enabled by supplying a &lt;code&gt;heartbeat.action.query&lt;/code&gt; configuration option in the connector&amp;#8217;s configuration. This property is meant to supply a SQL statement that the connector will execute periodically.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The initial implementation of the heartbeat action query was specifically for PostgreSQL to handle dealing with WAL growth under specific conditions. But a heartbeat action query has many uses and is entirely connector or even user driven.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, you may want to notify downstream consumers that your MySQL topology has changed by supplying consumers with an event with the GTID. The following configuration shows how to capture changes from the heartbeat action query table that can then be consumed easily by your CDC pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;gtid_history&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;heartbeat.action.query&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;INSERT INTO gtid_history( select * from mysql.gtid_executed )&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configurable_transaction_topic_names&quot;&gt;Configurable transaction topic names&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium transaction metadata topic had previously used a relatively non-configurable naming convention of &lt;code&gt;&amp;lt;database.server.name&amp;gt;.transaction&lt;/code&gt;. While it was possible to manipulate the topic name using a single message transform (SMT) as a workaround, we felt that allowing this to be a bit more flexible in Debezium proper made sense.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A new configuration option, &lt;code&gt;transaction.topic.prefix&lt;/code&gt;, has been introduced that allows the connector configuration to adjust the naming of the transaction metadata topic. The configuration option value specifies what will be used as a direct replacement for the `&amp;lt;database.server.name&amp;gt;~ portion of the topic name. If this configuration option is not supplied, the prior topic naming behavior will continue to be used; requiring no changes for existing connector deployments.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Invalid default value error on captured table DDL with default value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3710&quot;&gt;DBZ-3710&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental snapshot doesn&amp;#8217;t work without primary key &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4107&quot;&gt;DBZ-4107&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Signal based incremental snapshot is failing if database name contains dash &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4244&quot;&gt;DBZ-4244&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha2%20ORDER%20BY%20component%20ASC&quot;&gt;45 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/abhishekkh&quot;&gt;Abhishek Hodavdekar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, and &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_1_7&quot;&gt;Debezium 1.7&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition to this release, we also released Debezium 1.7.1.Final, a bugfix update for the 1.7 series. The 1.7.1.Final release includes many of the bugfixes in the 1.8 series that have been done since 1.7.0.Final. For more information on what changed in 1.7.1.Final, please see the &lt;a href=&quot;https://debezium.io/releases/1.7/release-notes#release-1.7.1-final&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The holiday season is upon us, but we intend to stick to our release cadence as closely as possible. If you haven&amp;#8217;t already taken an opportunity, we&amp;#8217;d love your feedback on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. In the meantime, you can expect the first beta release of 1.8 in a couple of weeks.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, 1.8.0.Alpha2! With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes: MySQL support for heartbeat action queries Configurable transaction topic name In addition, the latest 1.2 tag of the debezium/tooling image is available. The newest version includes all the latest tools, including kcctl, a super simple, cuddly CLI for Apache Kafka Connect.</summary></entry><entry><title type="html">Debezium 1.8.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha1 Released"/><published>2021-10-27T00:00:00+00:00</published><updated>2021-10-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_change_streams_support&quot;&gt;MongoDB Change Streams Support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MonogoDB &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/&quot;&gt;change streams&lt;/a&gt; allow an application or client access to real-time change data capture events without the complexity of tailing the oplog. This functionality was first introduced by the MongoDB engine in version 3.6; however the functionality was limited. Starting with MongoDB 4.0, change streams now captures changes across a database, replica set, or even a sharded cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium added change streams support to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Enable compatibility with MongoDB 5 (not yet tested, see future work below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide full document output in update events (see below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Abstract from internal (and potentially changing) specifics of the oplog format, making this new implementation a potential replacement for oplog reading in the future.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use change stream support with Debezium, you must use MongoDB 4.0 or later.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;enablement&quot;&gt;Enablement&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium for MongoDB exposes a new configuration property called &lt;code&gt;capture.mode&lt;/code&gt;. The capture mode specifies how the connector should obtain change events from the MongoDB database. The valid options are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;oplog&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by tailing the oplog; this is the legacy behavior.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will not contain the full message; only changed fields are part of the event.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_update_full&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will contain a full snapshot of the current record in the event. This is the new default for the connector.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The new &lt;code&gt;change_streams&lt;/code&gt; and &lt;code&gt;change_streams_update_full&lt;/code&gt; capture modes are incubating and the format and details surrounding how these work may change in future releases.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;event_changes&quot;&gt;Event changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using our tutorial from our &lt;a href=&quot;https://www.github.com/debezium-examples&quot;&gt;examples repository&lt;/a&gt;, lets take a look at the differences in these capture modes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, lets add a new record to our &lt;code&gt;customers&lt;/code&gt; collection. Using the MongoDB shell, this can be done by running the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.insert([ { _id : NumberLong(&amp;quot;1005&amp;quot;), first_name : 'Bob', last_name : 'Hopper', email : 'thebob@example.com', unique_id : UUID() } ]);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This will generate a change event but as you&amp;#8217;ll see if you inspect the topic, the contents of the event are not all that different in this release. Since the event is an insert, all field values provided in the emitted event.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During updates, this is where we can see the capture mode differences in action. Now modify the customer&amp;#8217;s first and last name using the MongoDB shell with this command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.update( { _id:NumberLong(&amp;quot;1005&amp;quot;) }, { $set: { first_name: &amp;quot;Bobby&amp;quot;, last_name: &amp;quot;Copper&amp;quot; } });&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This modifies the first and last name of the customer with id &lt;code&gt;1005&lt;/code&gt;. The following sections show what each event will look like for the given capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;oplog&quot;&gt;Oplog&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;oplog&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$v&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: 1, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$set&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: { &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;3510217852938498600&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250803&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event&amp;#8217;s after field has no value. Instead, the event provides values for patch and filter that describe limited details about what changed in the source document. Since the event only provides details about what fields have changed and not the values for unchanged fields, this may not be ideal for certain consumers that require knowledge of the full document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams&quot;&gt;Change Streams&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448736&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event has a slightly different set of values than the legacy oplog output. As shown above, the event does not have a value in the after, patch, or filter fields. Instead, the event relies on describing the changes to the document&amp;#8217;s fields in the &lt;code&gt;updateDescription&lt;/code&gt; structure. While this provides a bit more detail about values that may have been set and even unset due to an update, this may still not be ideal for some consumers that need values for all fields of the source document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams_full_document&quot;&gt;Change Streams Full Document&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams_update_full&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;thebob@example.com&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;unique_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$binary&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;KRywzYp5RneNu8DUmhQHAQ==&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$type&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;04&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878244&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This capture mode is nearly identical to the &lt;code&gt;change_streams&lt;/code&gt; mode except with one critical difference, the &lt;code&gt;after&lt;/code&gt; field is populated with a complete snapshot of document. This mode is great for consumers that rely on having all fields in the source document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please see the &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/#lookup-full-document-for-update-operations&quot;&gt;MongoDB documentation&lt;/a&gt; for more details on full document mode semantics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The full document mode is based on a re-selection of the source document when MongoDB provides the change event over the change stream to the connector. In cases where multiple changes to the same document happen within close proximity of one another, each event may have the same full document representation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;future_work&quot;&gt;Future work&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In conjunction to the work already done with MongoDB change streams, we recognize there is much work that remains which includes testing the new change streams implementations against MongoDB 5 and updating the connector documentation to reflect these new changes. You can expect this and much more as a part of the next preview release. As per the updated Debezium 1.8 &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt;, we&amp;#8217;re also planning to add support for incremental snapshots to the Debezium connector for MongoDB, as well as a variant of the outbox event router which supports the event format of this connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Row hashing in LogMiner Query not able to differentiate between rows of a statement (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3834&quot;&gt;DBZ-3834&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk select statement is incorrect for combined primary key in incremental snapshot (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3860&quot;&gt;DBZ-3860&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;column.the mask.hash.hashAlgorithm.with&amp;#8230;&amp;#8203;. data corruption occurs when using this feature (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4033&quot;&gt;DBZ-4033&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan SPI throws NPE with more than one connector configured to the same Oracle database (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4064&quot;&gt;DBZ-4064&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;82 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/cburch824&quot;&gt;Christopher Burch&lt;/a&gt;, &lt;a href=&quot;https://github.com/kometen&quot;&gt;Claus Guttesen&lt;/a&gt;, &lt;a href=&quot;https://github.com/famartinrh&quot;&gt;Fabian Martinez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gkorland&quot;&gt;Guy Korland&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/lbroudoux&quot;&gt;Laurent Broudoux&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/unalsurmeli&quot;&gt;Ünal Sürmeli&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashulin&quot;&gt;Zongwen Li&lt;/a&gt;, and &lt;a href=&quot;https://github.com/lujiefsi&quot;&gt;陆杰&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the end of the year is just around the corner, we intend to press forward with the same vigor. We have started an &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. Your feedback is invaluable so let us know what you&amp;#8217;d like to see added, changed, or improved! In the meantime, you can also expect a minor bugfix release to the Debezium 1.7 series next week, as well as another preview release of the Debezium 1.8 series in a couple more weeks. Happy Streaming!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, 1.8.0.Alpha1! With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!</summary></entry><entry><title type="html">Using Debezium to Create a Data Lake with Apache Iceberg</title><link href="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/" rel="alternate" type="text/html" title="Using Debezium to Create a Data Lake with Apache Iceberg"/><published>2021-10-20T00:00:00+00:00</published><updated>2021-10-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg</id><content type="html" xml:base="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s start with a short description of the data lake concept: A &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_lake&quot;&gt;data lake&lt;/a&gt; is &quot;usually a central store of data including raw copies of source system data, sensor data, social data etc&quot;. You can store your data as-is, without having to first process the data and then run different types of analytics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_server_iceberg&quot;&gt;Debezium Server Iceberg&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As operational data typically resides in a relational database or a NoSQL data store, the question is how the data can be propagated into the data lake. This is where the &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; project comes in: Based on Debezium and Apache Iceberg, it lets you process realtime data change events from a source database and upload them to any object storage supported by Iceberg. So let&amp;#8217;s take a closer look at these two projects.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;/&quot;&gt;Debezium&lt;/a&gt; is an open source distributed platform for change data capture. Debezium extracts change events from a database&amp;#8217;s transaction log and delivers them to consumers via event streaming platforms, using different formats such as JSON, Apache Avro, Google Protocol Buffers and others. Most of the time, Debezium is used with Apache Kafka and Kafka Connect. But via Debezium Server, also users of other messaging infrastructure like Kinesis, Google Pub/Sub, Pulsar can benefit from Debezium&amp;#8217;s change data capture capabilities. Here you can see the currently &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_sink_configuration&quot;&gt;supported destinations&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Apache Iceberg&lt;/a&gt; is an &quot;open table format for huge analytic datasets. Iceberg adds tables to compute engines including Spark, Trino, PrestoDB, Flink and Hive, using a high-performance table format which works just like a SQL table.&quot; It supports ACID inserts as well as row-level deletes and updates. It provides a Java API to manage table metadata, like schemas and partition specs, as well as data files that store table data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apache Iceberg has a notion of &lt;a href=&quot;https://iceberg.apache.org/spec/#version-2-row-level-deletes&quot;&gt;data and delete files&lt;/a&gt;. Data files are the files Iceberg uses behind the scene to keep actual data. Delete files are the immutable files to encode rows that are deleted in existing data files. This is how Iceberg deletes/replaces individual rows in immutable data files without rewriting the files. In the case of Debezium Server Iceberg, these are immutable &lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Apache Parquet&lt;/a&gt; files, a format which is designed as an &quot;efficient as well as performant flat columnar storage format of data compared to row based files like CSV or TSV files&quot;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;the_apache_iceberg_consumer&quot;&gt;The Apache Iceberg Consumer&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium Server provides an SPI to &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_implementation_of_a_new_sink&quot;&gt;implement new sink adapters&lt;/a&gt;, and this is the extension point used for creating the Apache Iceberg consumer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium-iceberg.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. Architecture Overview: Debezium Server and Apache Iceberg&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Iceberg consumer converts CDC change events to Iceberg data files and commits them to a destination table using the Iceberg Java API. It maps each Debezium source topic to a destination Iceberg table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a given Iceberg destination table is not found, the consumer creates it using the change event schema. Additionally, the event schema is used to map the change event itself to an equivalent Iceberg record. Because of this, the &lt;code&gt;debezium.format.value.schemas.enable&lt;/code&gt; configuration option must be set. Once the Debezium change event has been recorded into an Iceberg record, the schema is removed from the data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On a high level, change events processed as follows. For each received batch of events:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The events are grouped per destination Iceberg table; each group contains list of a change events coming from a single source table, sharing the same data schema&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;For each destination, events are converted to Iceberg records&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Iceberg records are saved as Iceberg data and delete files (delete files are created only if the consumer is running with upsert mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The files are committed to the destination Iceberg table (i.e. uploaded to the destination storage)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The processed change events marked as processed with Debezium&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here is a complete example configuration for using Debezium Server with the Iceberg adaptor:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.type=iceberg # run with append mode debezium.sink.iceberg.upsert=false debezium.sink.iceberg.upsert-keep-deletes=true debezium.sink.iceberg.table-prefix=debeziumcdc_ debezium.sink.iceberg.table-namespace=debeziumevents debezium.sink.iceberg.fs.defaultFS=s3a://S3_BUCKET); debezium.sink.iceberg.warehouse=s3a://S3_BUCKET/iceberg_warehouse debezium.sink.iceberg.type=hadoop debezium.sink.iceberg.catalog-name=mycatalog debezium.sink.iceberg.catalog-impl=org.apache.iceberg.hadoop.HadoopCatalog # enable event schemas debezium.format.value.schemas.enable=true debezium.format.value=json # complex nested data types are not supported, do event flattening. unwrap message! debezium.transforms=unwrap debezium.transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState debezium.transforms.unwrap.add.fields=op,table,source.ts_ms,db debezium.transforms.unwrap.delete.handling.mode=rewrite debezium.transforms.unwrap.drop.tombstones=true&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;upsert_and_append_modes&quot;&gt;Upsert and Append Modes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, the Iceberg consumer is running in upsert mode (&lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;). This means that when a row is updated in the source table, the destination is row replaced with the new updated version. And when a row is deleted from the source, it also is deleted from the destination. When using upsert mode, data at the destination is kept identical to the source data. The upsert mode uses the Iceberg equality delete feature and creates delete files using the key of the Debezium change data events (derived from the primary key of the source table). To avoid duplicate data, deduplication is done on each batch and only the last version of the record kept. For example in a single batch of events, the same record could appear twice: once when it is inserted, and another time when it gets updated. With upsert mode, always the last extracted version of the record is stored in Iceberg.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note that when a source table doesn&amp;#8217;t define a primary key and there is also no key information available by other means (e.g. a unique key or a custom message key defined in Debezium), the consumer uses the &lt;code&gt;append&lt;/code&gt; mode for this table (see below).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;keeping_deleted_records_with_upsert_mode&quot;&gt;Keeping Deleted Records With Upsert Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For some use cases it is useful to keep deleted records as a soft delete. This is possible by setting the &lt;code&gt;debezium.sink.iceberg.upsert-keep-deletes&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt;. This setting will keep the latest version of deleted records in the destination Iceberg table. Setting it to false will remove deleted records from the destination table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;append_mode&quot;&gt;Append Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This is the most straightforward operation mode, enabled by setting &lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. When using Debezium Server Iceberg with append mode, all received records are appended to the destination table. No data deduplication or deletion of records is done. With append mode it is possible to analyze entire change history of a record.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It also is possible to consume realtime events and do &lt;a href=&quot;https://iceberg.apache.org/maintenance/&quot;&gt;data compaction&lt;/a&gt; afterwards with a separate compaction job. Iceberg supports compacting data and metadata files to increase performance.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;optimizing_batch_sizes&quot;&gt;Optimizing Batch Sizes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium extracts and delivers database events in real time, and this could cause too frequent commits to the tables in Iceberg, generating too many small files. This is not optimal for batch processing, especially when a near-realtime data feed is sufficient. To avoid this problem, it is possible to increase the batch size per commit.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When enabling the &lt;code&gt;MaxBatchSizeWait&lt;/code&gt; mode, the Iceberg consumer uses Debezium metrics to optimize the batch size. It periodically retrieves the current size of Debezium&amp;#8217;s internal event queue and waits until it has reached &lt;code&gt;max.batch.size&lt;/code&gt;. During the wait time, Debezium events are collected in memory (in Debezium&amp;#8217;s internal queue). That way, each commit (set of events processed) processes more records and consistent batch size. The maximum wait and check interval are controlled via the &lt;code&gt;debezium.sink.batch.batch-size-wait.max-wait-ms&lt;/code&gt; and &lt;code&gt;debezium.sink.batch.batch-size-wait.wait-interval-ms&lt;/code&gt; properties. These settings should be configured together with Debezium&amp;#8217;s &lt;code&gt;debezium.source.max.queue.size&lt;/code&gt; and &lt;code&gt;debezium.source.max.batch.size&lt;/code&gt; properties.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here&amp;#8217;s an example for all the related settings:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.batch.batch-size-wait=MaxBatchSizeWait debezium.sink.batch.batch-size-wait.max-wait-ms=60000 debezium.sink.batch.batch-size-wait.wait-interval-ms=10000 debezium.sink.batch.metrics.snapshot-mbean=debezium.postgres:type=connector-metrics,context=snapshot,server=testc debezium.sink.batch.metrics.streaming-mbean=debezium.postgres:type=connector-metrics,context=streaming,server=testc # increase max.batch.size to receive large number of events per batch debezium.source.max.batch.size=50000 debezium.source.max.queue.size=400000&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;creating_additional_data_lake_layers&quot;&gt;Creating Additional Data Lake Layers&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At this point, the raw layer of the data lake has been loaded, including data deduplication and near realtime pipeline features. Building curated layers on top (sometimes called analytics layer or data warehouse layer) becomes very straightforward and simple. At the analytics layer, raw data is prepared to meet the analytics requirement; usually raw data is reorganized, cleaned, versioned (see example below), aggregated, and business logic may be applied. Using SQL through scalable processing engines is the most common way of doing this kind of data transformation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, someone could easily use &lt;a href=&quot;https://Iceberg.apache.org/spark-writes/&quot;&gt;Spark SQL&lt;/a&gt;(or PrestoDB, Trino, Flink, etc) to load a &lt;a href=&quot;https://en.wikipedia.org/wiki/Slowly_changing_dimension&quot;&gt;slowly changing dimension&lt;/a&gt;, the most commonly used data warehouse table type:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;MERGE &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;USING&lt;/span&gt; ( &lt;span class=&quot;comment&quot;&gt;-- new data to insert&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; customer_id, name, effective_date, to_date(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;9999-12-31&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;yyyy-MM-dd&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers &lt;span class=&quot;keyword&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;-- update exiting records. close end_date&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; t.customer_id, t.name, t.effective_date, s.effective_date &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers s &lt;span class=&quot;keyword&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; ) s &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; s.effective_date = t.effective_date &lt;span class=&quot;comment&quot;&gt;-- close last records/versions.&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;, t.end_date = s.end_date &lt;span class=&quot;comment&quot;&gt;-- insert new versions and new data&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;NOT&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt;(customer_id, name, current, effective_date, end_date) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt;(s.customer_id, s.name, &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;, s.effective_date, s.end_date);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Additional data lake layers may need to be updated periodically with new data. The easiest way of doing this is using SQL update or delete statements. These SQL operations are also &lt;a href=&quot;https://iceberg.apache.org/spark-writes/&quot;&gt;supported by Iceberg&lt;/a&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; prod.db.table &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; ...; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.table &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; ts &amp;gt;= &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-05-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; ts &amp;lt; &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-06-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.orders &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; t1 &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXISTS&lt;/span&gt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; order_id &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.returned_orders &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; t1.order_id = order_id; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; prod.db.all_events &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; session_time = &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, ignored = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; session_time &amp;lt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;predefined&quot;&gt;min&lt;/span&gt;(session_time) &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.good_events));&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;wrap_up_and_contributions&quot;&gt;Wrap-Up and Contributions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Based on Debezium and Apache Iceberg, &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; makes it very simple to set up a low-latency data ingestion pipeline for your data lake. The project completely open-source, using the Apache 2.0 license. Debezium Server Iceberg still is a young project and there are things to improve. Please feel free to test it, give feedback, open feature requests or send pull requests. You can see more examples and start experimenting with Iceberg and Spark using &lt;a href=&quot;https://github.com/ismailsimsek/iceberg-examples&quot;&gt;this project&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Ismail Simsek</name></author><category term="debezium"/><category term="iceberg"/><category term="datalake"/><category term="lakehouse"/><summary type="html">Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs. In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.</summary></entry><entry><title type="html">Incremental Snapshots in Debezium</title><link href="https://debezium.io/blog/2021/10/07/incremental-snapshots/" rel="alternate" type="text/html" title="Incremental Snapshots in Debezium"/><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/07/incremental-snapshots</id><content type="html" xml:base="https://debezium.io/blog/2021/10/07/incremental-snapshots/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the major improvements in Debezium starting in version 1.6 is support for &lt;a href=&quot;/documentation/reference/connectors/mysql.html#_ad_hoc_snapshot&quot;&gt;incremental snapshots&lt;/a&gt;. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;why_incremental_snapshots&quot;&gt;Why Incremental Snapshots?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the biggest pain points in Debezium since its inception was the sup-optimal support for changes to the captured tables list. As a user, you create a new connector with a list of tables to be captured (&lt;code&gt;table.include.list&lt;/code&gt; and related options); at a later point in time, it may become necessary to adjust this configuration, so to capture further tables which where not part to CDC initially. If it suffices to only &lt;em&gt;stream&lt;/em&gt; changes from these tables, then the problem is pretty simple to solve. But what if you also need to capture the existing contents of the tables?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Capturing existing data in tables is traditionally done by Debezium in the &lt;em&gt;snapshot&lt;/em&gt; phase. This phase is executed once upon the first connector start-up, and its objective is capturing consistent data at a point of time (transforming data at rest into data in motion). This can be a fairly long operation, and by definition, it must be executed completely or not at all - a bit like transaction semantics. This means that if the snapshot is not completed due to a connector restart for instance, it must be re-executed from scratch, and everything already done is thrown away. Also, while the snapshot is taken, any data modifications that are executed in parallel in the database are not streamed until the snapshot has been completed. This could lead to problems with database resources for very large snapshots, as transaction logs must be kept available until the streaming is started.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are thus ended up with three issues to be solved:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The near-impossibility of adding of additional tables to the captured tables list, if existing data must be streamed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A long-running process for consistent snapshotting that cannot be terminated or resumed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Change data streaming being blocked till the snapshot is completed&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;legacy_solutions&quot;&gt;Legacy Solutions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The problem was well known, and over time we developed workarounds and also ideated possible improvements and new solutions. As a workaround, the general recommendation was to use a multiple connector approach. The user was asked to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Stop the connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create a new one to take the snapshot of new tables (using the &lt;code&gt;initial_only&lt;/code&gt; snapshotting mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;When completed, stop the new connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Reconfigure and start the old connector with newly captured tables added to the list&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This method somewhat did the trick, but is very clumsy, and all the questions around snapshot consistency mentioned above still apply.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next step was a community contribution into the Debezium connector for MySQL via &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-175&quot;&gt;DBZ-175&lt;/a&gt;. It was based on the notion of having multiple binary log readers in place. One reader would capture the originally configured tables, while the other one will snapshot the new tables and then capture changes from the new tables. The latter reader would catch up with the original one, and then they would be reconciled and merged into a single one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The code was working well, but it never left the incubating stage, as the process itself was quite complex and liable to errors in corner cases. Last but not least, it was an ingenious approach, but unfortunately not portable to other connectors.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;watermark_based_snapshots&quot;&gt;Watermark-based Snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In late 2019, the Netflix engineering team announced that they had developed an in-house change data capture framework. They also came up with an innovative solution of executing concurrent snapshots using &lt;em&gt;watermarking&lt;/em&gt;, described in the paper &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt; DBLog: A Watermark Based Change-Data-Capture Framework&lt;/a&gt; by Andreas Andreakis and Ioannis Papapanagiotou.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The main idea behind this approach is that change data streaming is executed continuously together with snapshotting. The framework inserts low and high watermarks into the transaction log (by writing to the source database) and between those two points, a part of the snapshotted table is read. The framework keeps a record of database changes in between the watermarks and reconciles them with the snapshotted values, if the same records are snapshotted and modified during the window.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This means that the data is snapshotted in chunks - no lengthy process at the connector start, and also in case of crashes or a controlled termination of the connector, the snapshotting can be resumed since the last completed chunk.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As per Netflix, the implementation is provided for MySQL and PostgreSQL databases.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;signalling_table&quot;&gt;Signalling Table&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Before moving to Debezium&amp;#8217;s implementation of the watermark-based snapshotting approach, a small detour is needed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Sometimes it can be useful to control Debezium from the outside, so to force it to execute some requested action. Let&amp;#8217;s suppose it is necessary to re-snapshot an already snapshotted table - a so-called &lt;em&gt;ad-hoc&lt;/em&gt; snapshot. The user would need to send a command to Debezium to pause the current operation and do the snapshot. For that purpose, Debezium defines the concept &lt;em&gt;signals&lt;/em&gt;, issued via a &lt;a href=&quot;/documentation/reference/configuration/signalling.html&quot;&gt;signalling table&lt;/a&gt;. This is a special table, designated for communication between the user and Debezium. Debezium captures the table and when the user requires a certain operation to be executed, they simply write a record to the signalling table (sending a signal). Debezium will receive the captured change and then execute the required action.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_in_debezium&quot;&gt;Incremental Snapshotting in Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we became aware of DBLog&amp;#8217;s snapshotting approach, we decided that the method is a universal one and that we could try to adopt it in Debezium, too. Also as we share a lot of codebase among the different connectors (using the Debezium connector framework) our objective was to implement it in the Debezium core component, so that all connectors would benefit from the feature at once. The design and implementation were driven by the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;DDD-3&lt;/a&gt; Debezium design document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting in Debezium is available in form of ad-hoc snapshots. The user does not configure the connector to execute the snapshot, but instead they use the signalling mechanism to send a snapshot signal and thus trigger a snapshot of a set of tables. The signal in question is called &lt;code&gt;execute-snapshot&lt;/code&gt; and the signal message follows the format of:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-1&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-2&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-3&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;]}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a table snapshot is requested, then Debezium will do the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Obtain the largest primary key in the table; this is the snapshot endpoint, and its value is stored in the connector offsets&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Split the table into chunks based on the primary key&amp;#8217;s total order and of a size as prescribed by the &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; configuration option&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a chunk is queried, a dynamic SQL statement is built, selecting the next &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; records, whose primary keys are larger than the last one from the previous chunk (or the first primary key for the first chunk) and which are smaller or equal to the recorded maximum primary key.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The default chunk size is 1,024. You may increase the value for efficiency purposes (a smaller total number of snapshot queries will be executed), but this should be balanced with the increased memory consumption needed for the buffer. It is recommended to do some experimentation in your own environment to identify the setting working best for your situation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The reading of a chunk is a slightly complicated procedure:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk query is executed and the chunk content is read into memory&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Why is this needed? Why it is not enough to just query the database? The answers lie in the following picture:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/transactions.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. The transaction isolation&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is not the only process accessing the database. We can expect a multitude of processes accessing the database concurrently, potentially accessing the same records which currently are snapshotted. As shown in the picture, any changes to data are written to the transaction log based on the commit order. As it is not possible to precisely time the chunk read transaction to identify potential conflicts, the open and close window events are added to demarcate the time in which the conflicts can happen. Debezium&amp;#8217;s task is the deduplication of those conflicts.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For that purpose, Debezium records all events generated by the chunk into a buffer. When the &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is received, then all events coming from the transaction log are checked whether they belong to the snapshotted table(s). If yes, then the buffer is checked whether it contains the primary key. If yes, then the snapshot event is dropped from the buffer, as this is a potential conflict. And as it is not possible to correctly order the snapshot and transaction log events, only the transaction log event is kept. When the &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is received, the remaining snapshot events in the buffer are sent downstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following image shows an example of how such a buffer works and how are the transaction log events are filtered before being sent downstream:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/windowprocessing.png&quot; style=&quot;max-width:70%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. The buffer in action&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Records K2, K3, and K4 exist already in the database. Before the snapshot window opens, records K1 gets inserted, K2 updated, and K3 deleted. These events are sent downstream as they are read from the log. The snapshot windows opens, and its query selects K1, K2, and K4 into the buffer. While the window is open, the deletion of K4 is retrieved from the transaction log; the snapshot event for K4 is dropped from the buffer and the deletion event is sent downstream. K5 and K6 are inserted, which is retrieved from the log, corresponding events will be emitted. Depending on the specific timing, there may be read events for them in the buffer too (in the image that&amp;#8217;s the case for K5), which would be dropped. When the snapshot window closes, the remaining snapshot events for K1 and K2 will be emitted from the buffer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;connector_restarts&quot;&gt;Connector Restarts&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By now we have demonstrated that, using the notion of incremental snapshots, the same table(s) can be snapshotted repeatedly, if and when needed, while the connector is running. We have shown that its execution does not stop streaming from the transaction log. The last item is pausing and continuation of the process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When an incremental snapshot is running, then incremental snapshot context is added to each of the message offsets. The context is represented by three pieces of information:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The list of tables to be snapshotted where the first one is the one currently snapshotted&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The maximum primary key of the table&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The primary key of the last event from incremental snapshot sent downstream&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These three items are enough to resume the snapshot after a connector restart, be it intentionally or after a crash. Upon connector start, the component responsible for the snapshotting reads the data from the offsets. It initializes its internal state and resumes snapshotting after the last processed event. Note that any records which were inserted or updated while the connector wasn&amp;#8217;t running, will be processed via the regular stream reading, i.e. they are not subject to the ongoing snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This approach ensures the robustness of the process, resilience to restarts and crashes, and minimizes the number of redelivered events (at-least-once delivery semantics still apply).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;limitations&quot;&gt;Limitations&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The incremental snapshotting has few drawbacks in comparison to the initial consistent snapshot:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The snapshotted table must contain primary keys&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is deleted from the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and a &lt;code&gt;delete&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only a &lt;code&gt;delete&lt;/code&gt; event is be received&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is updated in the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and an &lt;code&gt;update&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;An &lt;code&gt;update&lt;/code&gt; event and &lt;code&gt;read&lt;/code&gt; event are received (note the opposite order)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only an &lt;code&gt;update&lt;/code&gt; event is received (in case the update happened within the chunk that would have emitted the &lt;code&gt;read&lt;/code&gt; event, causing that &lt;code&gt;read&lt;/code&gt; event to be discarded during de-duplication)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In general, &lt;code&gt;read&lt;/code&gt; events should not be understood as the initial state of the record in a table, but as the state of the record at an arbitrary point of time. Semantics for consumers are slightly changed in comparison to traditional initial snapshots in Debezium, while it will be guaranteed that a consumer has received the complete data set after an incremental snapshot has been completed, there won&amp;#8217;t be &lt;code&gt;read&lt;/code&gt; (snapshot) events for all records, but it could be &lt;code&gt;update&lt;/code&gt; events instead. The same goes for &lt;code&gt;delete&lt;/code&gt; events: consumers must be prepared to receive such events for records they had not seen before.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Having discussed the general concepts, let&amp;#8217;s explore things a bit more in an example. We will use our standard &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial&quot;&gt;tutorial deployment&lt;/a&gt; to demonstrate ad-hoc incremental snapshotting. We are using &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#using-postgres&quot;&gt;PostgreSQL&lt;/a&gt; as the source database. For this demo, you will need multiple terminal windows.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the beginning we will start the deployment, create the signalling table, and start the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 1 - start the deployment # Start the deployment export DEBEZIUM_VERSION=1.7 docker-compose -f docker-compose-postgres.yaml up # Terminal 2 # Create a signalling table echo &amp;quot;CREATE TABLE inventory.dbz_signal (id varchar(64), type varchar(32), data varchar(2048))&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Start Postgres connector, capture only customers table and enable signalling curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; -H &amp;quot;Content-Type:application/json&amp;quot; http://localhost:8083/connectors/ -d @- &amp;lt;&amp;lt;EOF { &amp;quot;name&amp;quot;: &amp;quot;inventory-connector&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.debezium.connector.postgresql.PostgresConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;database.hostname&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.port&amp;quot;: &amp;quot;5432&amp;quot;, &amp;quot;database.user&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.password&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.dbname&amp;quot; : &amp;quot;postgres&amp;quot;, &amp;quot;database.server.name&amp;quot;: &amp;quot;dbserver1&amp;quot;, &amp;quot;schema.include&amp;quot;: &amp;quot;inventory&amp;quot;, &amp;quot;table.include.list&amp;quot;: &amp;quot;inventory.customers,inventory.dbz_signal&amp;quot;, &amp;quot;signal.data.collection&amp;quot;: &amp;quot;inventory.dbz_signal&amp;quot; } } EOF&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the log we see that as per the &lt;code&gt;table.include.list&lt;/code&gt; setting only one table is snapshotted, &lt;code&gt;customers&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;connect_1 | 2021-09-24 13:38:21,781 INFO Postgres|dbserver1|snapshot Snapshotting contents of 1 tables while still in transaction [io.debezium.relational.RelationalSnapshotChangeEventSource]&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next step we will simulate continuous activity in the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 3 # Continuously consume messages from Debezium topic for customers table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.customers # Terminal 4 # Modify records in the database via Postgres client docker-compose -f docker-compose-postgres.yaml exec postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;i=0; while true; do psql -U $POSTGRES_USER postgres -c \&amp;quot;INSERT INTO customers VALUES(default,'name\$i','surname\$i','email\$i')\&amp;quot;; ((i++)); done&amp;quot;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic &lt;code&gt;dbserver1.inventory.customers&lt;/code&gt; receives a continuous stream of messages. Now the connector will be reconfigured to also capture the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;# Terminal 5 # Add orders table among the captured curl -i -X PUT -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/inventory-connector/config -d @- &amp;lt;&amp;lt;EOF { &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;, &quot;tasks.max&quot;: &quot;1&quot;, &quot;database.hostname&quot;: &quot;postgres&quot;, &quot;database.port&quot;: &quot;5432&quot;, &quot;database.user&quot;: &quot;postgres&quot;, &quot;database.password&quot;: &quot;postgres&quot;, &quot;database.dbname&quot; : &quot;postgres&quot;, &quot;database.server.name&quot;: &quot;dbserver1&quot;, &quot;schema.include&quot;: &quot;inventory&quot;, &quot;table.include.list&quot;: &quot;inventory.customers,inventory.dbz_signal,inventory.orders&quot;, &quot;signal.data.collection&quot;: &quot;inventory.dbz_signal&quot; } EOF&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As expected, there are no messages for the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now let&amp;#8217;s start an incremental ad-hoc snapshot by sending a signal. The snapshot messages for the &lt;code&gt;orders&lt;/code&gt; table are delivered to the &lt;code&gt;dbserver1.inventory.orders&lt;/code&gt; topic. Messages for the &lt;code&gt;customers&lt;/code&gt; table are delivered without interruption.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 # Send the signal echo &amp;quot;INSERT INTO inventory.dbz_signal VALUES ('signal-1', 'execute-snapshot', '{\&amp;quot;data-collections\&amp;quot;: [\&amp;quot;inventory.orders\&amp;quot;]}')&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Check messages for orders table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you were to modify any record in the &lt;code&gt;orders&lt;/code&gt; table while the snapshot is running, this would be either emitted as a &lt;code&gt;read&lt;/code&gt; event or as an &lt;code&gt;update&lt;/code&gt; event, depending on the exact timing and sequence of things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the last step, let&amp;#8217;s terminate the deployed systems and close all terminals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Shut down the cluster docker-compose -f docker-compose-postgres.yaml down&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post, we have discussed the motivation for the notion of incremental snapshotting, as introduced by the DBLog paper. We have reviewed the methods used in the past to achieve the described functionality. Then we dived into the deep waters of the implementation of this novel snapshotting approach in Debezium, and in the end we tried to use it live.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We hope you will find incremental snapshotting useful and we look forward to your feedback, experiences, and use cases. In a future blog post, we&amp;#8217;ll talk about the support for incremental snaphots of read-only databases (supported by the Debezium MySQL connector as of version 1.7) and how to trigger ad-hoc snapshots using a Kafka topic as the means of signalling instead of a database table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="db2"/><category term="snapshots"/><summary type="html">One of the major improvements in Debezium starting in version 1.6 is support for incremental snapshots. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.</summary></entry></feed>